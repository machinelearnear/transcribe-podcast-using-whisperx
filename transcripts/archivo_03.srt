1
00:00:01,300 --> 00:00:05,582
Hello again to the channel, if this is your first time here, what we do is Spanish divulgation of the latest

2
00:00:05,602 --> 00:00:10,623
that is coming out in Machine Learning. Today what we are going to be talking about is the new release that

3
00:00:10,663 --> 00:00:18,566
Microsoft did, which is 365 Copilot, which is basically introducing GPT-4, which came out yesterday,

4
00:00:18,646 --> 00:00:23,047
within the Office suite. So in this video we are going to do an analysis of everything that is

5
00:00:23,087 --> 00:00:26,088
happening this week in AI and also how this new tool can change the way

6
00:00:26,108 --> 00:00:27,089
in which you work.

7
00:00:31,671 --> 00:00:37,592
So, as always, we are going to divide the video into parts, first we are going to see what is happening this week in AI,

8
00:00:37,732 --> 00:00:38,792
I mean, put it in context, right?

9
00:00:39,252 --> 00:00:42,533
I mean, this release, in the middle of what things are coming out.

10
00:00:42,973 --> 00:00:47,114
Then we will see in detail what is this Microsoft 365 Copilot,

11
00:00:47,214 --> 00:00:50,035
and then we will see basically a conclusion,

12
00:00:50,055 --> 00:00:54,876
and we will see my ideas, my opinion, for example, in what is the future of work.

13
00:00:55,856 --> 00:00:55,936
and

14
00:00:56,757 --> 00:01:00,900
So, first of all, let's see what's happening this week, which was crazy, really.

15
00:01:01,461 --> 00:01:04,003
On Monday, Stanford released a paper called ALPACA.

16
00:01:04,623 --> 00:01:07,025
ALPACA is this paper, basically what they did is,

17
00:01:07,145 --> 00:01:10,027
they took a release that Meta had released last week, called LAMA,

18
00:01:10,088 --> 00:01:13,510
and what they did was use the API of OpenAI, DaVinci 3,

19
00:01:13,670 --> 00:01:14,431
Create. Share. Learn.

20
00:01:19,617 --> 00:01:25,379
based on that output, they generated a dataset that would be a supervised training of what they are doing,

21
00:01:25,499 --> 00:01:33,343
it is called self-instruction, the method they used, and using this dataset they trained a smaller version of Lama,

22
00:01:33,483 --> 00:01:38,525
that is, they did a fine-tuning, and then they generated a model called Alpaca, which is trained to do this task,

23
00:01:38,866 --> 00:01:43,027
which is good to do a little brainstorming of creative ideas to design blah blah blah

24
00:01:43,769 --> 00:01:53,674
and the good thing is that this file, with this amount of parameters, can run on a GPU with 7 or 10 GB of memory

25
00:01:53,754 --> 00:01:59,358
so it is something that you can use for games, let's say you can use it to run this type of models

26
00:01:59,698 --> 00:02:04,040
It has also been seen running on a MacBook, for example the latest M1 and M2.

27
00:02:04,882 --> 00:02:08,003
It also works. So, the first thing they did was that.

28
00:02:08,163 --> 00:02:12,745
Google announces Medpalm, which is a language model trained in medicine,

29
00:02:12,825 --> 00:02:17,727
in biomedical data. On Tuesday, this was actually the last thing that happened in the day.

30
00:02:17,747 --> 00:02:20,168
The first thing that happened in the day was that Google took out...

31
00:02:21,129 --> 00:02:24,674
a API for its generative models and released something called Maker Suite,

32
00:02:24,834 --> 00:02:27,437
which would be like a UI on top of that.

33
00:02:27,557 --> 00:02:29,880
Adept raised 350 million dollars,

34
00:02:30,000 --> 00:02:33,144
Anthropic, which is another company that makes LLMs,

35
00:02:33,825 --> 00:02:36,268
finally released Cloud, which was in preview,

36
00:02:36,848 --> 00:02:38,050
Create. Share. Learn.

37
00:02:37,130 --> 00:02:42,812
And then we also had Google add to their workspaces this from Generative AI.

38
00:02:42,892 --> 00:02:45,252
Now, all these things, these four things,

39
00:02:45,773 --> 00:02:47,373
didn't matter to almost anyone

40
00:02:47,793 --> 00:02:50,394
because at night OpenAI took out GPT-4

41
00:02:50,434 --> 00:02:54,035
and directly absorbed all the oxygen that was in the room.

42
00:02:54,435 --> 00:02:58,596
To give you an idea, this is what Google took out here, which is pretty good.

43
00:03:00,316 --> 00:03:03,957
Let's see how it connects to Microsoft 365.

44
00:03:42,747 --> 00:03:42,847
ok

45
00:03:54,999 --> 00:03:57,240
So, let's go back a bit. What's going on here?

46
00:03:57,280 --> 00:03:58,780
It's reading the text from our emails,

47
00:03:58,800 --> 00:04:00,301
it's creating a summary of what we were having,

48
00:04:00,341 --> 00:04:01,141
are incorporating

49
00:04:05,444 --> 00:04:09,087
what the email is, that is, the conversations that we are having.

50
00:04:09,507 --> 00:04:13,250
Then it is generating new text, that is, a template of an email

51
00:04:13,570 --> 00:04:15,712
when we want to answer these people.

52
00:04:15,752 --> 00:04:19,454
Then here you can see that it is generating, we can

53
00:04:19,474 --> 00:04:22,416
make it shorter, elaborate, expand it, rephrase it

54
00:04:22,436 --> 00:04:24,398
or add some kind of feature to the text that we have.

55
00:04:24,638 --> 00:04:27,680
For example, in this case, let's make it a little bit funnier.

56
00:04:35,338 --> 00:04:37,339
and it changes the way it's written, right?

57
00:04:37,919 --> 00:04:41,341
Now it tells us to build a presentation

58
00:04:41,681 --> 00:04:43,022
based on this text you just read.

59
00:04:44,383 --> 00:04:46,744
You can see how it starts to generate slides

60
00:04:46,764 --> 00:04:49,286
and generate images.

61
00:04:49,426 --> 00:04:52,868
In this case, we're deciding that what we want is to create images.

62
00:04:53,028 --> 00:04:55,509
So it's combining a lot of APIs at the same time.

63
00:04:55,589 --> 00:04:58,651
and it is also a collaborative environment.

64
00:05:01,842 --> 00:05:02,982
We're having a conversation,

65
00:05:03,943 --> 00:05:07,465
and it tells us what it's talking about, transcribe it, and take notes.

66
00:05:07,825 --> 00:05:11,026
Next steps, what are the points of what was said, etc.

67
00:05:11,086 --> 00:05:15,088
Then it's taking a spreadsheet, an Excel sheet,

68
00:05:15,148 --> 00:05:23,893
and it's telling us to generate things based on the information in the Excel sheet.

69
00:05:23,913 --> 00:05:26,714
Help me write a thank-you note to the team, right?

70
00:05:34,849 --> 00:05:39,790
etc. Well, this is what Google Workspace came up with.

71
00:05:39,890 --> 00:05:42,051
Well, this didn't come out anywhere.

72
00:05:42,091 --> 00:05:44,491
I mean, we're not talking about this because directly

73
00:05:44,511 --> 00:05:47,832
GPT-4 absorbed absolutely all the oxygen from that.

74
00:05:48,412 --> 00:05:50,993
On Wednesday we already had Pytorch releasing version 2.0,

75
00:05:51,093 --> 00:05:53,534
mid-journey, Stripes, which has an integration with GPT,

76
00:05:53,554 --> 00:05:55,234
But today, today, what happened?

77
00:05:56,475 --> 00:06:19,008
Microsoft released a copilot for the 365 suite, which is the Office suite, so let's see a little bit what other things are happening, one thing that does not come out here is that at the same time that this happens, there was also another release within all this, which is the release of the Chinese version of ChatGPT, that is, China has a model called Ernie

78
00:06:19,450 --> 00:06:22,552
which was made by Baidu, which is the Google of China

79
00:06:22,993 --> 00:06:25,795
and it was released a short time ago

80
00:06:25,895 --> 00:06:28,057
and we can see here that it didn't go so well

81
00:06:28,497 --> 00:06:31,940
so the actions, I mean, they had to make a live presentation

82
00:06:32,040 --> 00:06:33,241
and in the end it was pre-recorded

83
00:06:33,942 --> 00:06:36,684
to save time, they pre-recorded it

84
00:06:36,824 --> 00:06:39,026
just in case, so it doesn't say anything bad

85
00:06:39,046 --> 00:06:40,908
So once this was seen, the shares fell 10%.

86
00:06:45,233 --> 00:06:51,438
now there was one thing that I asked myself and this is a bit of geopolitics in how China did to be able to

87
00:06:51,458 --> 00:06:56,361
train this model because there is one thing that is not commented so much is that within this

88
00:06:56,381 --> 00:07:03,707
war of the United States China envies that it is the company that makes the video cards or the

89
00:07:03,727 --> 00:07:08,190
chips that are used to train these models in general so that you have an idea the last

90
00:07:09,633 --> 00:07:11,715
NVIDIA card, which is the RTX 4090

91
00:07:11,775 --> 00:07:14,958
This video card, which costs about $ 1,500

92
00:07:15,098 --> 00:07:19,903
It has the same amount of computers, the same processing capacity

93
00:07:19,983 --> 00:07:22,205
that the most powerful supercomputer of 2007

94
00:07:27,272 --> 00:07:29,893
That's just to give you an idea of how much these video cards have evolved over time

95
00:07:29,953 --> 00:07:33,975
With this $1500 board we have the fastest supercomputer of 2007.

96
00:07:41,981 --> 00:07:55,073
Going back, in this trade war between the US and China, the US said that it forbids all US companies, like NVIDIA, to sell chips that are very advanced to China.

97
00:07:55,093 --> 00:08:04,061
so the idea is that this divergence is generated, that is, that China cannot reach the United States and that there is a divergence.

98
00:08:06,638 --> 00:08:12,519
Not only that, not only do I forbid you to sell, but to the people, that is, to the people who have double nationality,

99
00:08:12,539 --> 00:08:18,000
let's say American China, and who are working in China in something related to semiconductors,

100
00:08:18,700 --> 00:08:24,401
I'm going to remove the American citizenship, which is something strange, because you can't remove citizenship, it's something eternal,

101
00:08:24,421 --> 00:08:31,822
citizenship lasts forever, but they do it in this particular case because it is something of national security.

102
00:08:31,842 --> 00:08:31,922
So...

103
00:08:33,864 --> 00:08:42,487
This limitation means that China does not have access to the same capacities that all the other countries of the world have.

104
00:08:42,507 --> 00:08:46,289
let's say Europe and, for example, the United States.

105
00:09:00,573 --> 00:09:04,175
the A100, and they made a copy called A800

106
00:09:04,195 --> 00:09:09,056
which basically has a little difference in the speed at which it works

107
00:09:09,077 --> 00:09:12,718
there is no speed at which they connect inside a box, let's say there are several of these

108
00:09:12,798 --> 00:09:16,579
of these plates, they speak to each other at this speed.

109
00:09:19,801 --> 00:09:27,203
and what they did was, well, they lowered that speed to match the standard that the U.S. government had issued

110
00:09:27,463 --> 00:09:32,545
but in itself the board is exactly the same, it has the same computing capacity, that is, it is something sharp

111
00:09:32,585 --> 00:09:41,907
and seeing this, it is obvious that these companies, companies like Baidu, for example, are buying absolutely all these boards to train their models

112
00:09:41,927 --> 00:09:45,568
Surely, although this may have failed, we will see many more models coming from China.

113
00:09:50,650 --> 00:09:56,712
So, one thing that I thought was interesting, before getting directly into Copilot,

114
00:09:57,352 --> 00:10:04,794
is that, until now, and in this I work for the direct competition of Microsoft, which is not Google,

115
00:10:05,775 --> 00:10:10,256
and I have to say, I really respect how they did this launch.

116
00:10:10,316 --> 00:10:15,698
and this post by Vivek seemed very good to me as a summary of how the launch was.

117
00:10:16,339 --> 00:10:24,202
It's the right way to do it, it was several months of making noise before they came out,

118
00:10:24,242 --> 00:10:29,665
they took it out a little bit in Bing, they gave it to partners too,

119
00:10:29,685 --> 00:10:33,507
but those partners didn't tell him, you can talk about this if you don't do it quietly

120
00:10:35,528 --> 00:10:40,930
They said that GPT-4 will only be available for people who have a GPT-chat subscription

121
00:10:40,970 --> 00:10:44,411
So what they are doing, I know two people who have already done it, and I pay for it

122
00:10:44,451 --> 00:10:46,032
I pay the $20 I get just to try it, right?

123
00:10:50,174 --> 00:10:54,459
They went from doing research papers in Archive to doing marketing whitepapers

124
00:10:54,479 --> 00:10:59,046
because if you see the last technical report and the rate card that came out of GPT-4

125
00:10:59,066 --> 00:11:02,731
it doesn't say anything technical about how this system was made

126
00:11:08,743 --> 00:11:14,066
in these models, in all the benchmarks, but also GPT-4 can be put in Stanford.

127
00:11:14,326 --> 00:11:16,447
So it's very, very interesting how they did it.

128
00:11:16,467 --> 00:11:20,229
Why am I talking about this? Because this is how OpenAI launched,

129
00:11:20,269 --> 00:11:21,609
But if we go back to the week...

130
00:11:23,472 --> 00:11:26,094
Here there were several releases that happened at the same time, right?

131
00:11:26,154 --> 00:11:28,677
Anthropic released Cloud and Google released this as well.

132
00:11:28,977 --> 00:11:31,359
But how is it that nobody is talking about these things?

133
00:11:31,399 --> 00:11:35,643
I mean, they are terrible releases from a marketing point of view.

134
00:11:35,663 --> 00:11:40,808
So much was the repercussion of this OpenAI that even the CEO of Stability.AI

135
00:11:40,868 --> 00:11:44,532
and what it's saying here is, look, if you're working in OpenAI...

136
00:11:45,574 --> 00:11:51,175
I'm going to give you the same fee, the benefits, everything exactly the same that OpenAI is giving you,

137
00:11:51,315 --> 00:11:57,636
but so that you have to work with me and so that you can really do open artificial intelligence,

138
00:11:58,037 --> 00:12:00,137
because OpenAI is now making products, so it is closed.

139
00:12:00,157 --> 00:12:05,518
So what Matt says is, I'll pay you the same, get out of there, come with me, and let it be open.

140
00:12:12,188 --> 00:12:15,689
This was something that came out in the middle, I'm going to put a little bit of noise.

141
00:12:15,729 --> 00:12:18,090
In addition to this launch that some people may say is very fast,

142
00:12:18,150 --> 00:12:22,251
it is not very accelerated, they are not taking into account all the repercussions it may have.

143
00:12:22,591 --> 00:12:27,533
Well, at the same time, yesterday, they kicked out their team from Ethica, from AI.

144
00:12:27,553 --> 00:12:30,754
So this makes noise, at least, what they did here.

145
00:12:30,974 --> 00:12:34,555
But hey, we put all this aside and we are going to see directly

146
00:12:34,575 --> 00:12:36,215
what is this ad that Microsoft made.

147
00:12:58,713 --> 00:13:02,957
Thanks for watching!

148
00:13:34,316 --> 00:13:38,237
and

149
00:14:15,030 --> 00:14:21,052
I'm not so excited because I already saw this, so I don't change my mind, but I thought this was amazing.

150
00:14:21,072 --> 00:14:29,015
Now we are going to see each of these things in detail, but what I am going to say is that several of the things they showed here are the same as we saw in Google.

151
00:14:29,115 --> 00:14:34,237
So we can see how these two companies are competing directly in the same functionalities, they are very similar.

152
00:14:39,139 --> 00:14:43,000
so here we can see that eventually they will be fighting until one of the two

153
00:14:43,440 --> 00:14:48,541
is going to go up, but the same, make presentations, analyze

154
00:14:48,581 --> 00:14:55,922
excel spreadsheets, generate for example a meeting that we have, a zoom,

155
00:14:56,363 --> 00:15:00,523
make a transcript and after that transcription make the notes,

156
00:15:00,563 --> 00:15:01,984
the next points, etc.

157
00:15:03,485 --> 00:15:13,150
So one thing I wanted to show here is the blog post where they are announcing everything and here they explain a little more how they did all this

158
00:15:13,710 --> 00:15:20,394
But I wanted to go to this presentation that they did, all the links of this I also have in the description of the videos

159
00:15:20,414 --> 00:15:26,177
so now we are going to see a shorter version that is 8 minutes but I recommend you if you want to start watching it

160
00:15:27,579 --> 00:15:28,980
The longest version is about 30 to 40 minutes

161
00:15:29,021 --> 00:15:30,743
where they tell you in detail how these things work

162
00:15:54,177 --> 00:15:56,478
This is basically a message to Google

163
00:15:56,498 --> 00:15:58,838
Google is going to show that you can dance

164
00:15:58,858 --> 00:16:00,699
but I want you to know that we made them dance

165
00:16:00,719 --> 00:16:00,919
Awesome

166
00:16:00,939 --> 00:16:02,159
Well, this, let's see it

167
00:16:02,179 --> 00:16:02,499
comment

168
00:16:17,184 --> 00:16:25,126
So here it tells us a bit, let's see, I'm going to leave it with the subtitle so it's easier to comment on it.

169
00:16:25,166 --> 00:16:29,848
Let's put this a little faster, too.

170
00:16:30,008 --> 00:16:31,429
Well, what is it doing?

171
00:16:31,669 --> 00:16:36,931
It's a combination, here we can see that it's not just copying and pasting something to chat.gpt,

172
00:16:36,951 --> 00:16:40,492
but here what it's doing is connecting these three things.

173
00:16:40,852 --> 00:16:42,713
It's connecting large language models,

174
00:16:43,253 --> 00:16:48,415
Notice that it says models in plural, that is, it means that it is not only a large

175
00:16:48,435 --> 00:16:51,356
chatgpt model that is working, but there are several models that can be

176
00:16:51,376 --> 00:16:56,498
smaller and more optimized, surely, for some type of action that you want to

177
00:16:56,858 --> 00:17:01,620
do. Then they are combining it with a graph network, that is, what this is

178
00:17:01,640 --> 00:17:06,902
doing is connecting a lot of files, for example, data, events, etc.,

179
00:17:06,942 --> 00:17:08,422
of our team, of our culture.

180
00:17:11,104 --> 00:17:15,247
local accounts and then finally it is integrating them within the

181
00:17:15,307 --> 00:17:16,148
Microsoft 365 application.

182
00:17:16,168 --> 00:17:30,138
We can see that we are going to have it integrated in Word, Excel, PowerPoint,

183
00:17:30,239 --> 00:17:32,020
Outlook and also in Teams.

184
00:17:33,882 --> 00:17:55,874
and finally they also add a new option called business chat which is something that would come to be like a personal assistant in reality because now you are going to see it from several different interfaces in different applications you can talk to this chat and what it has is that this chat has memory of everything we talk about so if one logs in for example to chat gpt or what is the business chat

185
00:17:57,276 --> 00:18:02,920
for a special page, or for Bing, or for Teams, or for etc., you can have the same conversation

186
00:18:03,080 --> 00:18:05,722
and you can, for example, ask things like, what happened today?

187
00:18:05,742 --> 00:18:08,925
You can read my emails and tell me what happened

188
00:18:09,225 --> 00:18:11,787
So, effectively, this is a virtual assistant

189
00:18:12,448 --> 00:18:13,449
completely automatic.

190
00:18:16,779 --> 00:18:23,401
You can see the calendar, emails, meetings, contacts, all of this is what it is doing.

191
00:18:23,421 --> 00:18:29,604
Here what they also say is that, what is the end user that Microsoft wants?

192
00:18:29,764 --> 00:18:32,545
They are not normal users, those are the ones from Google.

193
00:18:32,565 --> 00:18:39,087
Google also has its part, which is companies, but generally it is end users, that is, normal users.

194
00:18:41,129 --> 00:18:46,953
What Microsoft wants is, Microsoft is involved in all the corporations on the planet, or in almost all of them, right?

195
00:18:46,973 --> 00:18:51,856
then what it is saying here is, look, all this that we are going to show you is behind

196
00:18:52,036 --> 00:18:59,401
of various layers of security, compliance, privacy and responsible AI as well.

197
00:19:03,940 --> 00:19:06,181
Here we can see what they are doing.

198
00:19:06,201 --> 00:19:09,603
From all the transcript, from all the conversation,

199
00:19:09,923 --> 00:19:11,344
all these people are talking at the same time,

200
00:19:11,364 --> 00:19:13,245
you can't hear anything, if that were the case.

201
00:19:13,265 --> 00:19:15,946
From all this conversation that these people are having,

202
00:19:16,006 --> 00:19:17,287
here you can ask a question to this,

203
00:19:17,327 --> 00:19:19,147
on this side would be this copilot,

204
00:19:19,167 --> 00:19:20,868
this menu with which we talk,

205
00:19:20,948 --> 00:19:23,309
and we can see how this text is being generated

206
00:19:23,329 --> 00:19:24,530
based on that transcription.

207
00:19:31,434 --> 00:19:34,456
what are the problems that are not solved and here it begins to tell us,

208
00:19:34,656 --> 00:19:46,284
no explanation, let's say what they propose to you, the proposal and so on, no explanation, proposal

209
00:19:46,344 --> 00:19:52,628
and we can see how we have it in different areas, so we are going to see the first one, the first one that

210
00:19:52,668 --> 00:19:57,090
does is within what is Excel and here we can see on the left we are going to have

211
00:19:58,493 --> 00:20:06,444
our tabular information and here on the right you can see how we start to ask questions

212
00:20:06,804 --> 00:20:12,652
our information. For example, here, show me a breakdown of the growth of sales of ProSwear.

213
00:20:15,942 --> 00:20:21,765
help me visualize what were the things that contributed to the decline in the growth of sales,

214
00:20:21,785 --> 00:20:28,788
right? Analyzing the data and here it tells you, well, I can generate, I can apply the colors and I can

215
00:20:28,848 --> 00:20:32,790
apply a color code to the tables to make it easier for you to see the trends, right?

216
00:20:36,132 --> 00:20:37,893
You can see how it was added directly.

217
00:20:38,173 --> 00:20:39,654
Now, here we ask a question.

218
00:20:39,674 --> 00:20:43,495
What would have happened if the reusable containers

219
00:20:43,535 --> 00:20:45,436
had maintained

220
00:20:45,876 --> 00:20:48,157
the same growth rate

221
00:20:48,197 --> 00:20:49,318
of the previous quarter?

222
00:20:49,338 --> 00:20:51,859
What would have happened? Analyzing the data

223
00:20:52,860 --> 00:20:54,260
and there it is answering us,

224
00:20:54,300 --> 00:20:55,961
that is, the total growth for

225
00:20:56,301 --> 00:20:58,102
ProSquare in the first quarter

226
00:20:58,122 --> 00:20:59,743
would have been 9% instead of 1%.

227
00:20:59,963 --> 00:21:02,424
It explains. It creates a model

228
00:21:02,984 --> 00:21:04,325
and here it generates

229
00:21:04,445 --> 00:21:05,706
a model based on this data.

230
00:21:06,707 --> 00:21:12,810
We can keep asking questions and let it explain to us how it was, the way it thought all this.

231
00:21:13,350 --> 00:21:18,973
Then we can add graphics, we can choose if we want to keep it, if we want to generate it again,

232
00:21:18,993 --> 00:21:21,934
which is what we want to do.

233
00:21:21,954 --> 00:21:26,616
Now here what it is showing us is, well, let's get out of Excel and we are going to put it in the email, right?

234
00:21:26,936 --> 00:21:27,837
So, here we can see that...

235
00:21:30,400 --> 00:21:38,007
We have a lot of emails that we have received and what we are asking Copilot is

236
00:21:38,027 --> 00:21:43,072
can you make a summary of this, show me simply the most important thing that you have here.

237
00:21:43,092 --> 00:21:50,479
So we do a catch up and you can see how it starts to show us only the most important things.

238
00:21:50,519 --> 00:21:50,719
and also

239
00:21:51,182 --> 00:22:06,958
Well, here what we are saying is, for example, give me a summary, I don't have a lot of time, I'm running, the truth is, I'm seeing that there is a huge e-mail thread, I want you to summarize it for me, and that's what we are seeing here, Conversation Summary.

240
00:22:07,460 --> 00:22:14,222
and then here we say draft with copilot and we tell it, well, I want you to generate me, for example,

241
00:22:14,242 --> 00:22:17,783
here are little things that we want, recommend me a later analysis or what do you want to do?

242
00:22:17,823 --> 00:22:20,823
and here I put custom and I tell it, well, I want you to

243
00:22:23,965 --> 00:22:32,328
make me a sketch of an email with all this info that I give you and also that you include the

244
00:22:32,368 --> 00:22:38,091
projected sales of the q1 of this document and here it is saying get into this document, read it

245
00:22:38,191 --> 00:22:42,953
and generate it. So this is the interesting part, we are not only doing a prompt,

246
00:22:43,033 --> 00:22:47,975
generate me such a thing, but we are giving a reference to an external file and we say

247
00:22:48,035 --> 00:22:51,877
analyze that file, get all the information that you think is relevant, put it in the prompt and

248
00:22:51,897 --> 00:22:53,277
and generate something new.

249
00:22:54,379 --> 00:23:02,142
And here we can see how it starts to combine all the information we saw there, but it also combines graphics that it is taking out.

250
00:23:04,563 --> 00:23:14,587
Here we can see how we can also change, adjust the tone, make it a little shorter, change the tone to a more professional tone, neutral, casual, etc.

251
00:23:15,847 --> 00:23:19,689
you can see how we can change it

252
00:23:28,673 --> 00:23:32,176
So, we already saw what was email, what was Excel,

253
00:23:32,196 --> 00:23:35,539
and let's see how this system of copilot works.

254
00:23:35,599 --> 00:23:37,141
And this is what they are explaining here.

255
00:23:37,161 --> 00:23:38,182
We have three aspects.

256
00:23:38,222 --> 00:23:40,664
We have a system that feeds on three things.

257
00:23:46,732 --> 00:23:50,673
First, what we are going to do is, through the applications that we have here on the left,

258
00:23:50,753 --> 00:23:55,634
the 365 applications, what we are doing is, we are doing a prompt,

259
00:23:55,835 --> 00:23:59,676
we are talking to the system, to the assistant, to Copilot, we are asking for something, for example,

260
00:24:00,136 --> 00:24:02,877
give me the sales estimates for the next quarter.

261
00:24:04,197 --> 00:24:11,140
Copilot does a pre-processing of that prompt that the user sent us,

262
00:24:11,160 --> 00:24:16,021
so that it is written in a better way, so that the model can understand it,

263
00:24:15,962 --> 00:24:23,187
And we go to this GraphNetwork that we have of all the things that are ours.

264
00:24:23,787 --> 00:24:28,110
So, what we are doing here is basically generating a megadrive.

265
00:24:28,812 --> 00:24:34,454
prompt, that is, we are going to use, we are going to have the initial prompt, for example, the user, if you remember how

266
00:24:34,594 --> 00:24:40,156
gpt4 worked, it was, we establish the system, we tell it how we want the system to behave,

267
00:24:40,196 --> 00:24:47,299
for example, an AI that works very well, is an expert in numbers, it is a counter that knows how to

268
00:24:48,039 --> 00:24:53,721
generate sales projections, blah blah blah, that is your system, then within the user prompt

269
00:24:53,741 --> 00:24:54,501
we put what I wanted to know.

270
00:24:55,302 --> 00:25:02,124
and after that we put all the partial information of the documents in which we want to get the information,

271
00:25:02,184 --> 00:25:10,787
which can be a Word document, it can be a presentation, it can be an Excel, it can be emails, it can be a contact list, it can be a lot of things.

272
00:25:10,807 --> 00:25:19,390
I'm going to take this out. Once it takes out this information that we have here, emails, files, meetings, chats, calendars, contacts.

273
00:25:20,191 --> 00:25:26,434
Once it gets all that information, it puts it in the prompt and sends it to the language model.

274
00:25:26,734 --> 00:25:29,435
And we can say that this is a GPT chat, GPT-4, etc.,

275
00:25:29,455 --> 00:25:34,197
that receives a giant prompt with all this information and generates the answer.

276
00:25:34,257 --> 00:25:37,779
And now, the answer is...

277
00:25:38,681 --> 00:25:44,706
It doesn't go directly to where we had the user, right?

278
00:25:44,726 --> 00:25:52,032
So the answer goes back to this to be able to get all the sources from where we get the information.

279
00:25:52,052 --> 00:25:55,635
You saw that before we had asked the system to explain where such a thing comes from,

280
00:25:55,655 --> 00:25:57,156
why the sales are this, explain it to me.

281
00:25:57,236 --> 00:25:58,257
Well, that explanation...

282
00:26:00,920 --> 00:26:06,305
is because it is going back to the graph network that we had here

283
00:26:06,365 --> 00:26:11,749
and it is getting the references of the files, where they came from, which part of the file

284
00:26:12,590 --> 00:26:16,053
the information that is using the language model to send it came from.

285
00:26:16,073 --> 00:26:18,055
and one thing that it also does

286
00:26:19,077 --> 00:26:23,559
is that it checks that the answer it is giving, that is, it goes through a filtering system,

287
00:26:23,939 --> 00:26:28,421
so that the answer it is giving is not, if you remember, that it is not aggressive,

288
00:26:28,441 --> 00:26:35,084
discriminatory, racist, not useful, that it is a lie, that is, that it is not

289
00:26:35,604 --> 00:26:41,787
factually correct, etc. And once all those tests are passed, it returns to the application again.

290
00:26:41,827 --> 00:26:43,948
So, every time we write...

291
00:26:43,508 --> 00:26:46,269
And there it says, for example, generating a response and it takes 1 or 2 seconds.

292
00:26:46,289 --> 00:26:47,830
It's doing all of this that we see here.

293
00:26:47,850 --> 00:26:54,491
So, in this case, you can see how one thing that can be done is,

294
00:26:54,511 --> 00:26:59,132
this seemed to me to be tricky, here's a meeting and you say,

295
00:26:59,152 --> 00:27:04,134
no, man, I'm not going to make it. No, I'm not going to make it because I'm doing something else.

296
00:27:04,174 --> 00:27:08,195
It doesn't look good. But I want to follow, so I click follow.

297
00:27:08,735 --> 00:27:11,655
What this does is that now the meeting is going to happen.

298
00:27:13,257 --> 00:27:22,843
and I can ask for a recap of the meeting, that is, a summary of what happened, I didn't go to the meeting, but I want to know what happened anyway, well, I'll give you the summary, don't worry,

299
00:27:23,303 --> 00:27:27,666
It gives you the summary, it gives you the notes, it does the things you have to do.

300
00:27:27,327 --> 00:27:33,229
And it also shows you a video that matches with when things were said.

301
00:27:33,249 --> 00:27:36,070
So you can keep asking questions here.

302
00:27:36,310 --> 00:27:39,691
For example, what other clients were discussed and what factors were considered?

303
00:27:39,711 --> 00:27:40,551
All of this.

304
00:27:40,631 --> 00:27:43,452
Why? Because he is reading the transcription of the whole meeting.

305
00:27:47,268 --> 00:27:51,852
and there you can see how we start to have... and if we want to see where that comes from, we can have the reference

306
00:27:51,872 --> 00:27:57,397
directly in which part of the conversation was said to see that it is real, that is, we say this, but what did he really mean?

307
00:27:57,457 --> 00:28:03,943
And it returns us the part in the transcription where it happened.

308
00:28:03,963 --> 00:28:06,805
which is what we have here, right?

309
00:28:17,892 --> 00:28:23,338
This weird part says, how does the group feel about the inventory status?

310
00:28:23,438 --> 00:28:27,742
The group seems to have mixed feelings about the inventory status.

311
00:28:27,762 --> 00:28:32,367
On one hand they are happy, blah blah blah. I don't know how reliable this is but

312
00:28:32,387 --> 00:28:34,570
It's giving us that information, at least.

313
00:28:39,416 --> 00:28:52,402
And well, what we have here is also very interesting, it is something that Google already showed us, more or less how it worked, so it is not so different, but in this case we have an application where all the people, that is, several people are

314
00:28:53,804 --> 00:28:59,847
collaborating at the same time with this, so this is something crazy because it is not that there are

315
00:28:59,867 --> 00:29:03,609
many applications where you can do this type of collaboration with AI as well,

316
00:29:03,629 --> 00:29:11,973
that is, all these users at the same time are talking with Copilot and they are having, let's say,

317
00:29:11,993 --> 00:29:15,795
this generation of content at the same time, with the same system that has access to the same

318
00:29:15,815 --> 00:29:20,117
files, possibly, so we can see it as something interesting.

319
00:29:22,065 --> 00:29:43,469
And this, what they are saying here at the end, is the whole part of Responsible AI, what they are saying is, look, we can have errors, what is important is that we also put mechanisms so that when we are wrong, they can give us a feedback of, you were wrong here, see if you can fix it.

320
00:29:47,385 --> 00:30:02,723
So what it is saying is, look, this is actually an assistant, it is not going to solve your life, it is simply an assistant and in this case, for example, of any result that it gives you, you will be able to adjust the result, and here, for example, what we are seeing can be the short, medium, long, long text,

321
00:30:08,137 --> 00:30:14,983
So the idea is that this gives you an initial help to start your work,

322
00:30:15,163 --> 00:30:19,948
that it is not simply something that you take for granted,

323
00:30:19,988 --> 00:30:22,149
but that it simply gives you an idea to start.

324
00:30:22,189 --> 00:30:25,713
One thing that is not seen here is the whole part of the presentations,

325
00:30:26,033 --> 00:30:27,754
Again, this, if you see it...

326
00:30:28,737 --> 00:30:31,219
of the presentations, I mean PowerPoint.

327
00:30:31,699 --> 00:30:34,882
What do we have here? This is longer, it's about 40 minutes, right?

328
00:30:35,723 --> 00:30:39,025
I mean, this also seemed quite interesting to me.

329
00:30:39,105 --> 00:30:39,706
Let's see it.

330
00:30:42,988 --> 00:30:44,189
It was over here.

331
00:30:45,551 --> 00:30:46,111
No, it's this.

332
00:30:48,294 --> 00:30:50,956
What is this? Well, basically the same, right? The same thing we saw from Google.

333
00:30:51,637 --> 00:30:54,279
It takes a lot of information and tells you to generate a presentation.

334
00:30:54,619 --> 00:30:57,962
What I found interesting is that before this, you can actually have a text document.

335
00:30:57,982 --> 00:30:58,523
Right? This text document.

336
00:30:58,543 --> 00:31:01,525
And then you tell it,

337
00:31:01,545 --> 00:31:06,329
Hey, now what I want is for you to make a presentation of this text document.

338
00:31:06,349 --> 00:31:08,150
Right? So this is... I found it very cool, very interesting.

339
00:31:08,811 --> 00:31:08,891
Now.

340
00:31:14,997 --> 00:31:21,381
Having said this, we are going to stop here, we are going to make a conclusion and an idea of ​​the future of the work.

341
00:31:21,421 --> 00:31:23,722
I'm going to say a couple of things about this.

342
00:31:23,882 --> 00:31:28,685
First, all these tools are obviously new, some people can say impressive, like me, for example, I say this is impressive.

343
00:31:28,745 --> 00:31:34,108
Other people can say, shit, I'm going to lose my job, or this is going too fast, I can't keep up with these things.

344
00:31:38,852 --> 00:31:44,714
What I think in this case is, first of all, that now, at this moment, companies are accelerating

345
00:31:44,754 --> 00:31:50,736
the, let's say, taking these products to the market. It doesn't mean that it will always be like this.

346
00:31:50,776 --> 00:31:54,757
I mean, it doesn't mean that this is exponentially growing. It may be that they are growing now,

347
00:31:54,777 --> 00:31:58,858
and then it becomes a plateau, and then eventually it will grow again.

348
00:31:58,898 --> 00:32:05,861
But what we are seeing here is a very fast transition from the research to the application of these ideas.

349
00:32:05,881 --> 00:32:06,721
which is interesting.

350
00:32:07,722 --> 00:32:10,304
I'm going to tell a story here, I have a friend, a madman...

351
00:32:12,507 --> 00:32:15,789
a guy from Sri Lanka, who works for Deloitte,

352
00:32:16,429 --> 00:32:19,631
he is an important consultant,

353
00:32:19,671 --> 00:32:22,593
and I remember he told me a story,

354
00:32:22,633 --> 00:32:24,214
that once he had to make a presentation,

355
00:32:24,234 --> 00:32:26,955
and in a similar situation, he had made a presentation

356
00:32:26,975 --> 00:32:28,376
and he was presenting it internally,

357
00:32:28,996 --> 00:32:30,497
and a person, his manager,

358
00:32:30,517 --> 00:32:33,019
looks at it and says, that presentation is wrong,

359
00:32:33,039 --> 00:32:35,120
why? He says that the formatting

360
00:32:35,200 --> 00:32:37,001
That is, the training is wrong in the way it is done.

361
00:32:39,165 --> 00:32:42,710
and it asks which part is wrong, and I say, no, no, no, look, tell me the blank spaces,

362
00:32:42,730 --> 00:32:48,058
For example here, between the L and the W, the ampersand, there is a blank space.

363
00:32:48,078 --> 00:32:49,119
well, tell me the amount of space and

364
00:32:52,206 --> 00:32:55,928
The one on the left had less space than the one on the right.

365
00:32:55,988 --> 00:32:58,809
And you say, how can it be that someone saw that?

366
00:32:58,829 --> 00:32:59,450
Well, this person saw it.

367
00:32:59,510 --> 00:33:02,391
I mean, the formatting was very important for this person in Deloitte.

368
00:33:02,411 --> 00:33:05,053
To the point that he stopped a whole presentation and said,

369
00:33:05,093 --> 00:33:06,513
count the blank spaces to see what was there.

370
00:33:06,573 --> 00:33:09,555
And yes, there was indeed a space that was a little bigger.

371
00:33:09,995 --> 00:33:10,335
Incredible.

372
00:33:10,355 --> 00:33:13,117
All that kind of things, those little things,

373
00:33:13,217 --> 00:33:15,718
are going to disappear with this kind of systems, right?

374
00:33:15,758 --> 00:33:18,540
I mean, the idea of this is that

375
00:33:19,300 --> 00:33:19,500
¡Lom!

376
00:33:20,722 --> 00:33:26,146
The important thing is not so much how these things are done, but the initial idea.

377
00:33:26,186 --> 00:33:29,668
These things are going to give you that beginning of creativity,

378
00:33:30,088 --> 00:33:34,732
but at the end of the day there will always be a person who is going to make the decision.

379
00:33:35,272 --> 00:33:40,656
So what I believe here is that clearly these machines are not going to replace people,

380
00:33:41,056 --> 00:33:43,718
but if people who know how to use these tools,

381
00:33:44,158 --> 00:33:47,260
it is very possible that they will replace people who do not know how to use these tools.

382
00:33:48,443 --> 00:33:56,730
So with this I do want to tell you something that I see a lot, I have a friend who works as a QA engineer

383
00:33:56,750 --> 00:34:03,175
and with him now, for example, what he can do is ask the GPT chat a lot of things

384
00:34:03,195 --> 00:34:04,836
how to make a program or how to make

385
00:34:05,439 --> 00:34:08,840
a new solution, etc. and he gives solutions that work.

386
00:34:09,001 --> 00:34:11,542
So maybe now he can be much more efficient in his work

387
00:34:11,582 --> 00:34:14,003
and he receives congratulations, for example,

388
00:34:14,344 --> 00:34:18,066
because he is doing things that are applied, that are useful, very fast.

389
00:34:18,586 --> 00:34:20,867
And he has the idea very quickly and can apply it.

390
00:34:23,771 --> 00:34:29,255
The people I work with, for example, have a lot of academic training.

391
00:34:29,275 --> 00:34:31,736
They have postdocs in machine learning and health.

392
00:34:31,756 --> 00:34:35,379
And I see that they reject the idea of using language models

393
00:34:35,419 --> 00:34:36,039
because if...

394
00:34:41,065 --> 00:34:47,330
they think it is something more of engineering rather than theory, it is not linked to research

395
00:34:47,550 --> 00:34:52,035
basically the ideas are like one and then you apply it in different domains

396
00:34:52,095 --> 00:34:58,981
but in reality the original idea is very simple, there is no very superior research to it.

397
00:34:58,942 --> 00:35:07,885
So, for this person, who already has an academic background, it is very difficult for him to open up to these new ideas

398
00:35:07,905 --> 00:35:12,766
that, since no one knows exactly how they work, they have much more practice than theory.

399
00:35:13,166 --> 00:35:16,967
So, in my opinion, in this case, we are seeing a kind of very accelerated social Darwinism

400
00:35:17,527 --> 00:35:23,348
where the ability to adapt to these new things is more important than the previous knowledge we had.

401
00:35:24,349 --> 00:35:28,850
So I would say that it is one of the best moments to get into everything that is machine learning

402
00:35:28,870 --> 00:35:31,491
even if it seems that this is very complex, it is not so complex

403
00:35:31,531 --> 00:35:36,932
and using these tools, the experience will be much more important than all that previous knowledge.

404
00:35:36,952 --> 00:35:38,373
That on the one hand.

405
00:35:38,453 --> 00:35:44,254
On the other hand, I think that what we are seeing here...

406
00:35:45,615 --> 00:35:59,045
within Microsoft compared to all other companies is, first of all, that we have different players in this space, we have Apple, we have Facebook, we have Google, we have Amazon, we have Microsoft, etc., and then we have many more, but these are the great ones in software.

407
00:36:00,628 --> 00:36:06,134
One thing that happened with Samsung, Samsung was always, always, always behind Sony, always.

408
00:36:06,735 --> 00:36:10,899
Even if they made better hardware, better products, they were always behind.

409
00:36:10,919 --> 00:36:15,164
Until the 90s, 2000s, where there was a change, which was to go from analog to digital.

410
00:36:15,565 --> 00:36:17,547
In that case, Sony was very good.

411
00:36:18,189 --> 00:36:28,774
It was excellent, Sony, in everything it was, it dominated the market, but Samsung then used that moment of transition as a moment to surpass Sony.

412
00:36:28,914 --> 00:36:32,396
Why? Because Sony wasn't that interested in making that transition

413
00:36:32,736 --> 00:36:35,297
because maybe their money came from the analogue part.

414
00:36:37,439 --> 00:36:41,841
So, a very interesting thing that happened with Samsung

415
00:36:41,861 --> 00:36:44,402
is that they hired a marketing vice-president named Lee

416
00:36:44,482 --> 00:36:47,463
and what this guy said was

417
00:36:47,643 --> 00:36:50,424
change absolutely everything except your wife and children.

418
00:36:50,544 --> 00:36:52,305
And what I wanted to say with this is

419
00:36:52,685 --> 00:36:54,886
we have to change the way we talk about the company,

420
00:36:54,906 --> 00:36:58,287
we present it to the company, we think about the company completely.

421
00:36:58,989 --> 00:37:08,200
So what they did here was an absolute change and they chose to get into the digital market and they became the pioneers of that and they were able to surpass Sony.

422
00:37:08,960 --> 00:37:17,951
Why do I say this? Because what is happening here with Microsoft is that...

423
00:37:17,833 --> 00:37:23,975
these people are adding it very quickly, all these new things that are coming out, they are putting it in very quickly.

424
00:37:24,435 --> 00:37:27,616
Normally this is not the way it happens, if we go back again to see Google,

425
00:37:27,976 --> 00:37:34,658
that Google has the same, right? I mean, it just released the same, exactly the same, but why does it take so long?

426
00:37:34,918 --> 00:37:37,419
Why is Google the second to do this and not the first?

427
00:37:37,459 --> 00:37:39,339
I should have been the first, if you have...

428
00:37:40,941 --> 00:37:44,925
all the search, they have all our information, at least mine, they have it in the last 15 years

429
00:37:45,426 --> 00:37:50,651
in their database, so how is it that Google is coming second instead of coming first?

430
00:37:50,691 --> 00:37:55,717
So for me what is happening right now is something similar to this, which is a paradigm shift

431
00:37:56,037 --> 00:37:58,620
of Microsoft passing over Echoes.

432
00:37:59,483 --> 00:38:17,930
With this I do not want to say that Microsoft has won, but it is very interesting that this war is taking place and I hope, because eventually all this will advance the research in these areas, I hope that this will make Google and other companies begin to develop new things as well with all this, so with that I say goodbye.

433
00:38:19,132 --> 00:38:20,993
I hope this talk has been entertaining

434
00:38:21,153 --> 00:38:24,617
Again, these topics are very long, they are very long and they are very crazy

435
00:38:24,677 --> 00:38:30,742
So, well, any comment you have about this, I tried to comment it as best as possible

436
00:38:30,802 --> 00:38:36,567
If I forgot something, leave it in the comments, if you want to see something in particular, you can also leave it

437
00:38:36,587 --> 00:38:37,768
so I leave you a big hug and bye bye

