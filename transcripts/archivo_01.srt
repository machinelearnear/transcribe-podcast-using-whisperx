1
00:00:01,301 --> 00:00:12,849
Hello again to the channel, if this is your first time here, what I try to do is Spanish divulgation of things that are coming out in Machine Learning, trying to explain it in a way that is a little easier to understand and also to use.

2
00:00:12,869 --> 00:00:23,376
Today what I wanted to talk about is Alpaca, which is a new model that was trained by Stamford, based on a model called Lama from Meta, and how with very little money

3
00:00:25,999 --> 00:00:30,222
Comparatively, you can do something that works very well at the GPT chat level,

4
00:00:30,663 --> 00:00:34,666
but also that it can be more accessible and efficient for everyone.

5
00:00:35,688 --> 00:00:39,190
So, as always, we are going to divide the video into parts.

6
00:00:39,310 --> 00:00:44,212
First, I would like to talk about what this Stanford Alpaca model is.

7
00:00:44,252 --> 00:00:47,614
Then see a little what was the dataset that was used to train this model.

8
00:00:47,634 --> 00:00:48,915
Why is all this important?

9
00:00:49,015 --> 00:00:53,137
Then some crazy people, the truth, compiled this in C++.

10
00:00:53,157 --> 00:00:58,459
So this works very efficiently and uses very little hardware.

11
00:00:58,940 --> 00:01:02,461
And then someone also begins to give their opinion on how to train this model

12
00:01:02,481 --> 00:01:04,262
how much we would get, for example, to have

13
00:01:04,684 --> 00:01:10,411
a new version and finally we are going to see Cabrita which is a Brazilian version of Lama

14
00:01:10,431 --> 00:01:15,377
that was made to test the concept, how much would it really be needed for how much money

15
00:01:15,417 --> 00:01:21,544
you need to be able to have one of these modules so we are going to get to see all this and

16
00:01:23,228 --> 00:01:36,380
I'm going to try to cover a lot of things so it is possible that I forget several things or that I do not explain them in a very clear way, so I ask you to put in the comments any questions you have left after all this.

17
00:01:36,520 --> 00:01:42,165
I'm going to try to be as concise as possible, which is generally a bit difficult for me.

18
00:01:42,928 --> 00:02:01,686
Well, first of all, what is this about Alpaca? Well, Alpaca, 7 billion parameters, is a model that is a fine-tuned version of the Lama model that took the goal, that is, it is trained in 52,000 examples that follow instructions.

19
00:02:03,349 --> 00:02:19,360
The important thing about this is that what these people from Stanford found is that it works very similar to Davinci 003, which is GPT 3.5 and it is quite cheap to make this model, that is, it costs less than $ 600 and we are going to see exactly what it means.

20
00:02:19,380 --> 00:02:23,482
First of all, what is this llama thing? Let's go back a bit. What was this llama thing?

21
00:02:23,502 --> 00:02:24,283
Well, that's it.

22
00:02:29,047 --> 00:02:33,990
Facebook released just a few weeks ago these four models, 7,000, 13,000, 33,000, 65,000, millions of parameters.

23
00:02:34,010 --> 00:02:37,452
It trained them completely in public datasets, such as Crawl, C4, GitHub, Wikipedia, Books, etc.

24
00:02:37,792 --> 00:02:39,853
All this makes a total of about 4.75...

25
00:02:52,062 --> 00:03:00,648
terabytes of data and generates more or less, I think it's 1.4 trillion tokens, right?

26
00:03:00,668 --> 00:03:07,332
To put it in a comparison, when GPT-3 was trained, 300 billion tokens were used.

27
00:03:07,352 --> 00:03:11,795
And in this case we can see how the models, that is, the loss, the training loss,

28
00:03:11,975 --> 00:03:17,940
we can see that it always goes down, right? So this performance is pretty good, right?

29
00:03:17,960 --> 00:03:20,521
that is, the model of 7 billion parameters, perhaps

30
00:03:21,023 --> 00:03:26,465
If he had trained for more time, he would not have reached the same performance as the one of 13 billion parameters.

31
00:03:26,626 --> 00:03:33,109
So, what did Facebook do when it released these models?

32
00:03:33,369 --> 00:03:38,851
It made them open source, they had to be written down in a waitlist, but eventually the checkpoints were leaked

33
00:03:38,871 --> 00:03:41,412
and these models were going around everywhere.

34
00:03:41,432 --> 00:03:44,354
Now, what happened? What was the problem with this model?

35
00:03:44,374 --> 00:03:45,614
Well, the Lama model.

36
00:03:49,877 --> 00:03:52,380
It was trained to complete text, but not in instructions.

37
00:03:52,600 --> 00:03:54,422
So when you chatted with the model, it was pretty bad.

38
00:03:54,442 --> 00:03:54,823
Pretty bad.

39
00:03:54,843 --> 00:03:57,285
So here what Stanford is saying is,

40
00:03:57,305 --> 00:04:00,128
look, the models that follow instructions,

41
00:04:00,148 --> 00:04:02,050
such as GPT 3.5, ChatGPT, Cloud, and Bing's chat,

42
00:04:02,070 --> 00:04:03,992
they are becoming more and more powerful, right?

43
00:04:11,502 --> 00:04:25,389
So, what they are saying here is, well, here we are going to show you what are our results of having done a fine tuning on these models, right?

44
00:04:25,769 --> 00:04:28,150
Here they explain a little bit, etc., how they are doing everything.

45
00:04:28,170 --> 00:04:32,912
The interesting thing is that they do not make the models available for us to download, but

46
00:04:35,314 --> 00:04:41,541
Yes, they are giving us the code they used to train the model and also to generate the data.

47
00:04:42,202 --> 00:04:46,106
But hey, they tell us here that at some point we are going to get them out, we still don't know how.

48
00:04:46,706 --> 00:04:52,552
but what they did was put an interactive demo where we can interact with this model.

49
00:04:53,395 --> 00:05:00,780
One thing they are telling us is that the alpaca model is only for academic uses and any

50
00:05:00,820 --> 00:05:05,483
commercial use is completely prohibited. Why is it prohibited? For three things. First,

51
00:05:05,643 --> 00:05:13,448
Lama, these models have a non-commercial license, so all the variations that are made of

52
00:05:13,468 --> 00:05:19,251
that model are also non-commercial. Second, when they generated the dataset, and now we are going to see

53
00:05:19,471 --> 00:05:21,713
specifically how they did it, they used an OpenAI API.

54
00:05:23,315 --> 00:05:32,778
But if you get into the terms of use of this API, what it is telling you is that models that compete with OpenAI cannot be generated.

55
00:05:32,798 --> 00:05:38,900
So, Alpaca clearly competes with OpenAI, so this could not be used legally.

56
00:05:38,940 --> 00:05:45,123
and finally since they did not make any security measures then they say better

57
00:05:45,143 --> 00:05:48,444
we do not take out alpaca for general use, right?

58
00:05:50,706 --> 00:05:57,070
So, first of all, about Lama, I would like to say that I had made a video a while ago about this,

59
00:05:57,090 --> 00:06:02,353
so if you want to see it, there is a demo, there is also an explanation of the paper and there is a lot of information on that.

60
00:06:02,413 --> 00:06:06,916
I will put the links of everything you are seeing here in the description. So let's go back to this.

61
00:06:07,056 --> 00:06:11,018
How does this work to train or generate data? How was this information generated?

62
00:06:11,038 --> 00:06:11,919
Well, here what they are doing is...

63
00:06:16,522 --> 00:06:24,466
is that, what they say is, look, generally to train a good model that does, that can generate

64
00:06:24,486 --> 00:06:29,528
instructions without a lot of money, what we need is a

65
00:06:29,688 --> 00:06:29,788
and

66
00:06:29,409 --> 00:06:36,172
a good model of language and then we need some type of data that is of high quality,

67
00:06:36,693 --> 00:06:41,475
where these things are explained, how to follow instructions. Now we are going to see what that means.

68
00:06:41,915 --> 00:06:46,157
Generally, how is it done? For example, when the first paper came out, InstractGPT, which was the first

69
00:06:46,177 --> 00:06:46,717
version of ChatGPT.

70
00:06:50,460 --> 00:06:55,842
The way they did it was, they simply generated more or less about 50,000 examples,

71
00:06:56,122 --> 00:07:02,365
they paid people, they paid people and said sit down, start writing and write, for example, this instruction.

72
00:07:02,785 --> 00:07:05,487
I wrote a poem, etc. and then they put a person who writes the poem, right?

73
00:07:05,507 --> 00:07:08,608
So they did it like this 50,000 times and that was what they used to tell these language models,

74
00:07:08,628 --> 00:07:12,230
Look, it's fine how you behave with the English idiom, but I want you to...

75
00:07:17,293 --> 00:07:22,676
follow that you behave in this way, that is, that you know how to follow instructions basically,

76
00:07:22,696 --> 00:07:29,500
more similar to a conversation with a user. So here what it is telling us is, well,

77
00:07:29,520 --> 00:07:35,964
the first part, all this of the language model is very good, we already have it because that is what

78
00:07:36,064 --> 00:07:42,728
Lama does, we already know that they work quite well. Now for the second part we are going to follow a paper

79
00:07:42,748 --> 00:07:43,828
which is called Self-Instruct.

80
00:07:44,910 --> 00:07:49,673
what it is telling us is, look, we are going to use the same model that we said here, Lama,

81
00:07:50,474 --> 00:07:57,899
and we are going to use it to generate this instruction data, right? I mean, what does this mean?

82
00:07:57,919 --> 00:08:04,323
What it means is that we are going to start from 175 instructions, right? That are made by a person,

83
00:08:04,343 --> 00:08:06,584
that we can see here. If we open this and go to the paper

84
00:08:13,047 --> 00:08:20,411
which seems to me to be, well, now we are going to see it, I have the list, I have the list there of how the example is,

85
00:08:20,431 --> 00:08:23,393
but basically we have instructions that are similar in this way, right?

86
00:08:23,433 --> 00:08:26,395
I mean, we have the instruction that says, for example, in this case,

87
00:08:28,076 --> 00:08:32,859
brainstorm a list of possible things that I want to have done for the new year, right?

88
00:08:32,939 --> 00:08:37,722
And here we have that this is the instruction that we send it and the output that we expect from the model is

89
00:08:38,202 --> 00:08:39,603
lose weight, do more exercise, eat better.

90
00:08:40,445 --> 00:08:42,550
etc. Well, these things...

91
00:08:58,795 --> 00:09:06,518
Then what they say is, well, we are going to take these 175 examples and we are going to use them as a base

92
00:09:06,578 --> 00:09:11,879
to call the GPT-3 API from OpenAI and we are going to generate these 52,000 cases.

93
00:09:17,043 --> 00:09:28,275
So here you can see that they also gave us the code to be able to do it and they have it in the github that we are going to see in a while.

94
00:09:28,315 --> 00:09:34,461
When they did this, 50,000 examples, it cost them more or less about 500 dollars, that is, approximately

95
00:09:34,561 --> 00:09:35,723
one cent, for example.

96
00:09:36,325 --> 00:09:46,036
Imagine that you give this to, for example, some contracts and tell them to make me 50,000 examples of this.

97
00:09:46,456 --> 00:09:49,560
Obviously it's going to be a lot more expensive than a cent, for example.

98
00:09:50,323 --> 00:09:52,624
So, once we have these 52,000 examples of instructions,

99
00:09:52,644 --> 00:09:57,787
we do what is known as a supervised fine-tuning of the model, right?

100
00:09:58,007 --> 00:10:02,670
And for that, here what they are using is a training framework from HimeFace

101
00:10:02,710 --> 00:10:07,233
that can distribute the training in several GPUs, etc.

102
00:10:07,273 --> 00:10:10,575
here what they are saying is that we use three hours in eight

103
00:10:17,660 --> 00:10:18,700
NVIDIA A100, etc.

104
00:10:18,760 --> 00:10:21,701
This is, well, it cost $100 to do that.

105
00:10:21,721 --> 00:10:24,302
This is huge, huge, it's a

106
00:10:24,342 --> 00:10:27,643
giant cluster of computers, more or less this costs

107
00:10:27,663 --> 00:10:30,743
about $500,000. You can see that they used it

108
00:10:30,763 --> 00:10:32,964
here in cloud and, well, in three hours

109
00:10:33,304 --> 00:10:36,745
they can do it. But this, if you wanted to have a

110
00:10:36,805 --> 00:10:40,986
of this, it would be impossible to be able to do it.

111
00:10:40,408 --> 00:10:53,286
Well, how did they do the evaluation of this? They generated the results, they generated the model and then they began to evaluate it and the evaluation was done by the five people who made the paper that we have up here.

112
00:10:56,591 --> 00:11:02,033
and took an evaluation set and basically did what would be a blind test and compared the

113
00:11:02,073 --> 00:11:07,915
results the generations that had GPT 3.5 and alpaca and well they said that here alpaca wins 90 of 89 times

114
00:11:08,015 --> 00:11:13,258
in this about that so what they are basically saying is look at the model that we have just

115
00:11:13,318 --> 00:11:15,819
In general, it has the same performance as...

116
00:11:21,502 --> 00:11:27,525
gpt 3.5 at least in the tests that we have just done and here they have let's say these things

117
00:11:27,565 --> 00:11:32,547
here we can see that it is an alpaca as it is different from a llama and here it tells us good an alpaca

118
00:11:32,567 --> 00:11:37,549
is a domesticated species of a chameleon from South America related to llamas and

119
00:11:37,589 --> 00:11:43,932
vicuña is smaller than a llama and has good it has a fur that is thinner and softer blah blah

120
00:11:43,952 --> 00:11:48,314
blah blah blah no good this is an instruction so what are we saying we are asking a

121
00:11:48,334 --> 00:11:50,115
question, right?

122
00:11:49,816 --> 00:11:55,217
but basically we are talking to the model in a conversational way,

123
00:11:55,497 --> 00:11:57,577
first, and second is that we are giving it an instruction,

124
00:11:57,637 --> 00:12:00,038
how it is different from a llama, right?

125
00:12:00,538 --> 00:12:02,578
In this case, for example, here we tell it,

126
00:12:02,598 --> 00:12:05,999
write us an email to give our congratulations

127
00:12:06,479 --> 00:12:08,619
to the people who were admitted to Stanford

128
00:12:08,720 --> 00:12:12,120
and mention that you are also quite interested

129
00:12:12,200 --> 00:12:14,421
in getting to know all of them in person.

130
00:12:14,961 --> 00:12:16,882
Here we can see how it generates this example.

131
00:12:18,502 --> 00:12:24,444
People admitted from Stanford, congratulations on your admission to Stanford, bla bla bla.

132
00:12:24,464 --> 00:12:26,744
Pretty good, pretty good.

133
00:12:26,764 --> 00:12:29,945
So, it starts to tell us the limitations.

134
00:12:30,005 --> 00:12:34,226
The limitations are obviously that it has a limit of information.

135
00:12:34,326 --> 00:12:39,928
It has the same limits as GPT 3.5, which in this case doesn't have access to all the information.

136
00:12:41,770 --> 00:12:49,015
and also, well, that it lies, I mean, it doesn't lie but it hallucinates very easily, and also that it can generate

137
00:12:49,035 --> 00:12:51,437
answers that are toxic and discriminatory, etc.

138
00:12:51,678 --> 00:12:54,340
What did they do here?

139
00:12:54,982 --> 00:13:12,754
The last thing they say is, look, obviously this is quite risky what we are doing because we are telling people, for example, bad actors, that they can generate models that this can easily generate fake news, that is, it can very easily generate false posts and so on.

140
00:13:12,774 --> 00:13:16,036
So why are they going to make a model like this or a technique that...

141
00:13:19,660 --> 00:13:22,783
generates this possibility that bad negative results are generated socially

142
00:13:22,844 --> 00:13:27,889
Well, what they are saying here is, on the one hand, yes, it is possible that this happens, but on the other hand

143
00:13:27,969 --> 00:13:31,233
if we put it out, it will make people start to discuss these things

144
00:13:31,293 --> 00:13:32,614
and a defense mechanism is generated

145
00:13:32,654 --> 00:13:35,177
about these things, especially from the academic community.

146
00:13:39,604 --> 00:13:45,351
so this was exactly what happened so we are going to see now a little well how it works

147
00:13:45,371 --> 00:13:51,799
so well we saw this if I would like to talk a little bit about now how is the method

148
00:13:51,959 --> 00:13:55,704
this Self-Instruct that they used and in this case you can see here

149
00:13:56,487 --> 00:13:59,609
that we had the 175 initial tasks, this is what a human wrote,

150
00:13:59,629 --> 00:14:01,730
so what we do is we put it in randomly, each one is chosen,

151
00:14:01,750 --> 00:14:03,911
and a language model takes it as input and then we say

152
00:14:03,931 --> 00:14:06,812
Well, now that you know this input, generate me...

153
00:14:14,637 --> 00:14:20,061
one more or five more, for example, and we can see how it generates this instruction for us.

154
00:14:20,842 --> 00:14:25,626
Then what it does here is, once it generates this instruction for us, we have a second model

155
00:14:25,726 --> 00:14:35,233
that classifies it and tells us, for example, in this case, the instruction that we are giving it is

156
00:14:36,054 --> 00:14:39,817
if the text that I am going to give you next is in favor or against abortion.

157
00:14:40,437 --> 00:14:42,539
So, the class we are looking for is...

158
00:14:43,541 --> 00:14:49,963
pro-abortion and the input, the text, this is what the user is going to give, it would be, I believe that

159
00:14:50,003 --> 00:14:56,686
women should have the right to choose whether they want or do not want to have an abortion, for example

160
00:14:56,726 --> 00:15:01,988
in this case, so here we can see that in this case we have an output first, that is, we are

161
00:15:02,008 --> 00:15:06,670
generating all this and here we have the pair of what we are talking about, we have the instruction,

162
00:15:07,130 --> 00:15:10,531
we have the class and we have the input and this is what is going to be used later to do this

163
00:15:11,031 --> 00:15:12,112
supervised fine-tuning

164
00:15:13,333 --> 00:15:20,101
to the model. I would like to see here in the paper, here it explains a little more how it works.

165
00:15:23,045 --> 00:15:31,527
Here, one thing that I found interesting is that it tells us how the distribution of these generations of instructions is.

166
00:15:31,567 --> 00:15:41,829
You can see that, generally, if we look at the instruction, we see that these are the ways in which it is most divided.

167
00:15:41,849 --> 00:15:50,151
First we are saying, write me, give me, find, create, make, describe, design, and these are the ways in which it is distributed.

168
00:15:50,171 --> 00:15:50,231
So...

169
00:15:51,692 --> 00:16:00,097
If we give instructions to these models that are trained with this dataset and we put this verb as part of our instruction, it will work much better.

170
00:16:00,137 --> 00:16:03,019
Why? Because it was trained in this way.

171
00:16:03,059 --> 00:16:08,342
If we had generated the dataset in another way, it could be different.

172
00:16:08,382 --> 00:16:12,904
One thing I did want to say is that here we are saying that this,

173
00:16:12,924 --> 00:16:18,548
In other words, generating this data using OpenAI is...

174
00:16:20,430 --> 00:16:25,112
That's what OpenAI is saying. This violates my terms of use.

175
00:16:25,612 --> 00:16:28,533
But we can see that other models, for example this one,

176
00:16:28,553 --> 00:16:31,034
that I also made a video a while ago about this,

177
00:16:33,755 --> 00:16:37,297
for this paper, they used here, if we go further down,

178
00:16:37,317 --> 00:16:39,638
they used GPT-3 to generate the data.

179
00:16:39,738 --> 00:16:42,299
In this case they generated 400,000 examples of this data.

180
00:16:42,319 --> 00:16:43,980
It also seemed super smart what they did here.

181
00:16:47,082 --> 00:17:06,922
The truth is very good, the way they used it, but perhaps this is not violating the terms of use because the resulting model that we have here, let's say, does not compete with OpenAI in the sense that it does not compete with a language model, so this would be ok, but hey, a detail, here we can see

182
00:17:07,525 --> 00:17:12,929
the repo, you can see that this is all very recent, last week, we can see the repo here,

183
00:17:12,949 --> 00:17:19,194
you will see that there are three things that are available, we have the data, 52,000 examples, we have the

184
00:17:19,214 --> 00:17:23,718
code to generate the data, if we want to generate it ourselves, and we have the code to do the

185
00:17:23,738 --> 00:17:26,680
fine tuning of the model. If we open the data that we have here

186
00:17:28,643 --> 00:17:30,763
What do we have here?

187
00:17:30,783 --> 00:17:33,224
Sorry, we go here, that is, in data, it will show us that we have the file.

188
00:17:33,244 --> 00:17:36,625
And if we click on this file, we will see that this is how the data looks.

189
00:17:36,645 --> 00:17:39,246
When we talk about data, what are we talking about?

190
00:17:39,266 --> 00:17:41,747
Well, this is it. Here we have the instruction.

191
00:17:43,168 --> 00:17:49,672
give me three tips to stay healthy and we have the output. Well, eat a balanced diet

192
00:17:49,812 --> 00:17:56,455
and make sure to include a lot of fruits and vegetables, point two, exercise regularly to

193
00:17:56,535 --> 00:18:02,278
keep your body active and strong and three, well, sleep enough and keep a consistent sleep

194
00:18:02,298 --> 00:18:07,900
consistent blah blah blah. Well, this, but 52,000 times, this is what we use as a dataset, right?

195
00:18:11,323 --> 00:18:27,767
So, summary of all this, here again, this blog post is excellent, it is a summary that we have here, the last one that is coming out, we can see that there is, basically what is happening, this model came out, 7 billion parameters, well, people started to say

196
00:18:28,428 --> 00:18:49,686
Where can we run it? Well, we can run it on this GPU. No, something smaller. We can run it on this CPU. Where? No, on a Macbook. Yes, well, can it be a little less? Yes, it can be on, we run it on an iPhone. Well, perfect. Now where do we run it? We run it on an iPhone, on an Android. And now where? On a Raspberry Pi. And so on.

197
00:18:50,588 --> 00:18:53,530
I mean, the code, the inference of this started to be optimized a lot

198
00:18:54,070 --> 00:19:00,394
and this model started to become something that is very cheap to run.

199
00:19:00,434 --> 00:19:05,597
I mean, imagine this, that in time it can become that each one of us can have

200
00:19:08,180 --> 00:19:14,521
our phone, that is, not depending on an internet connection, for example, well here it gives us

201
00:19:14,541 --> 00:19:23,322
what would be a background of all this and we can see examples etc. What we have here is

202
00:19:23,502 --> 00:19:31,364
basically this, it is possible to train a model that has the same level, that is, Lama what it shows us

203
00:19:31,384 --> 00:19:34,124
that it is possible to enter a model that has the same quality as GPT-3, this

204
00:19:37,526 --> 00:19:39,247
that now we are going to see what it means,

205
00:19:39,267 --> 00:19:41,509
it shows us that it is possible to run these models

206
00:19:41,809 --> 00:19:43,631
in hardware that is available

207
00:19:43,731 --> 00:19:45,412
for anyone, and then finally

208
00:19:45,472 --> 00:19:46,813
Alpaca shows us that it is

209
00:19:47,314 --> 00:19:49,115
possible to generate

210
00:19:49,135 --> 00:19:50,516
a small dataset with about 500

211
00:19:50,556 --> 00:19:52,198
dollars and then train a model

212
00:19:52,218 --> 00:19:52,298
for

213
00:19:52,318 --> 00:19:55,120
relatively little money

214
00:19:55,280 --> 00:19:56,521
to have something that works

215
00:19:56,561 --> 00:19:57,502
very well, right?

216
00:20:01,207 --> 00:20:03,387
Well, here we can see the dataset and so on.

217
00:20:03,487 --> 00:20:05,627
Instruction, output, the same as we saw before.

218
00:20:06,128 --> 00:20:09,228
Why is all this important?

219
00:20:09,268 --> 00:20:13,289
Here is an article by Eliezer Zhukovsky,

220
00:20:13,309 --> 00:20:15,349
I thought it was very good.

221
00:20:15,409 --> 00:20:16,369
What the guy says is,

222
00:20:16,389 --> 00:20:18,350
look, I don't think people realize

223
00:20:18,370 --> 00:20:20,170
how big this whole Stanford thing is.

224
00:20:20,190 --> 00:20:20,670
The reason is this.

225
00:20:20,750 --> 00:20:22,731
If you have a giant model,

226
00:20:30,473 --> 00:20:38,418
For example, in this case, OpenAI has its huge model and gives access to people, to its API.

227
00:20:38,438 --> 00:20:41,379
That means that we can give it an input and we get an output.

228
00:20:41,399 --> 00:20:53,046
If we do it, if this happens, you are almost giving it the grandmother's jewel, what it says here.

229
00:20:53,286 --> 00:20:58,108
for others, for the competition, you can almost clone your model.

230
00:20:59,591 --> 00:21:06,997
without having the need for all that work that you put in to make your fine-tuning dataset.

231
00:21:07,197 --> 00:21:08,518
So, what did Stanford do here?

232
00:21:09,078 --> 00:21:13,642
Basically, what they did is, just like OpenAI had to pay people to make its 50,000-example dataset,

233
00:21:13,662 --> 00:21:18,126
which they probably paid them, I don't know, hundreds of thousands of dollars,

234
00:21:18,146 --> 00:21:19,207
They did it with 500 dollars, didn't they?

235
00:21:25,273 --> 00:21:32,235
I mean, we can see how the cost of the input barrier is getting lower and lower, right?

236
00:21:32,655 --> 00:21:39,337
So, basically what he is saying here is that

237
00:21:39,517 --> 00:21:43,038
why Stanford is not selling this access?

238
00:21:43,338 --> 00:21:48,759
Because basically he says, look, I don't want to get into legal mess with all these people

239
00:21:48,859 --> 00:21:52,880
but if you don't mind getting into legal mess or no one is going to find out

240
00:21:52,900 --> 00:21:55,601
You can easily use it.

241
00:21:54,241 --> 00:21:59,226
the access to this API to generate a model that is similar to GPT 3.5.

242
00:21:59,706 --> 00:22:02,088
and this is what it is telling us here.

243
00:22:03,831 --> 00:22:06,693
Basically, there is a thing called knowledge distillation,

244
00:22:06,793 --> 00:22:11,796
which is, for example, we have a huge, huge model

245
00:22:11,896 --> 00:22:13,457
that probably parts of that model,

246
00:22:13,597 --> 00:22:15,378
that is, the parameters of what were, are so many,

247
00:22:15,438 --> 00:22:17,160
are thousands of millions of parameters,

248
00:22:17,200 --> 00:22:19,321
many of those may contain very little information.

249
00:22:19,801 --> 00:22:21,762
So what you can do is distill the model

250
00:22:22,243 --> 00:22:27,146
only keeping the parameters that have a lot of information, right?

251
00:22:27,308 --> 00:22:41,526
If you think of this as a reduction of dimensionality, it could be when the dimensionality is reduced and we have, let's say, axes, for example, that contain the greatest variance, right?

252
00:22:41,566 --> 00:22:42,046
In this case...

253
00:22:43,550 --> 00:22:48,394
That would be to distill the model, not to grab a giant model and then re-train a smaller model.

254
00:22:48,634 --> 00:22:53,958
Well, this is super expensive, super expensive, and you have to have the giant model, access to the giant model to do it.

255
00:22:54,018 --> 00:23:01,463
Instead, what we are doing here with Alpaca is, we are simply doing a very small fine-tuning, right?

256
00:23:01,483 --> 00:23:02,184
So what he is saying here...

257
00:23:02,706 --> 00:23:11,512
is that basically unless these companies, the truth is, have the ability to

258
00:23:11,692 --> 00:23:16,276
or go to look for all the people who make these variations and put a demand on them

259
00:23:16,316 --> 00:23:22,461
immediately or if not, cut access to inputs and outputs, it will be very difficult that

260
00:23:22,841 --> 00:23:26,524
no one else can generate copies of these models, right?

261
00:23:27,346 --> 00:23:35,831
I mean, it's something pretty crazy, and over here it explains it, I think it's in a part here, I think it's this one.

262
00:23:35,592 --> 00:23:41,076
that it is not that someone got into your factory with a little camera and saw your entire

263
00:23:41,116 --> 00:23:46,280
manufacturing process, no, simply what you are seeing is that you enter wood or resources,

264
00:23:47,521 --> 00:23:50,624
that is, simply the resources inside your factory, then they see the product that comes out, a

265
00:23:50,644 --> 00:23:55,968
blender by n and simply by seeing what comes in and what comes out, they can already copy your blender,

266
00:23:56,108 --> 00:24:02,813
not your process of creating that blender, so it is very crazy in what direction all this will go

267
00:24:02,853 --> 00:24:05,595
all this, right? You have to see, a little bit.

268
00:24:05,477 --> 00:24:10,291
Well, we see why it is important, let's see a little bit now...

269
00:24:11,918 --> 00:24:20,964
Very quickly, this is the porting that was made to the Facebook model, from Lama to C++.

270
00:24:21,024 --> 00:24:29,729
So here, I'm not going to spend a lot of time with this, I'm just going to show you that this would be like your Stable Diffusion model.

271
00:24:29,750 --> 00:24:33,392
What happened? Stable Diffusion came out and a very short time later it exploded.

272
00:24:33,432 --> 00:24:34,312
This was in August 2022 but...

273
00:24:35,975 --> 00:24:39,237
In a few months, variations of everything started to come out.

274
00:24:39,257 --> 00:24:47,082
The community started to create a lot of things that made Stable Diffusion go ahead of MidJourney and DALI.

275
00:24:47,803 --> 00:24:56,328
Once the community had ownership of this, they were able to take it in a much more advanced direction.

276
00:24:56,348 --> 00:24:57,989
So maybe that's what is happening

277
00:24:58,951 --> 00:25:19,505
with Lama. Here we can see that initially they needed more or less a GPU, there is the A100, which is a GPU that costs $ 8,000 to run it and now with all these optimizations that were done we can run it with an app to play it on video games, that is, it is not much needed.

278
00:25:19,525 --> 00:25:23,988
Here we have it, Georgi Gervanov is the person who is doing it.

279
00:25:23,769 --> 00:25:29,752
what they say is a person who is in Sofia in Bulgaria and before he had done the porting of

280
00:25:29,832 --> 00:25:36,176
whisper and now he is doing it from llama, there is also another from alpaca, this one in particular is from llama

281
00:25:36,716 --> 00:25:41,319
and the way they do it is spectacular, there are several tricks of how it is working and

282
00:25:41,359 --> 00:25:47,142
Here we can see an example of how it is running on a notebook directly.

283
00:25:48,904 --> 00:25:57,512
This is something crazy, because before we said that to run something that looks like a GPT-3 we needed approximately $50,000 of hardware.

284
00:25:57,873 --> 00:25:59,875
And now we can run it on a notebook.

285
00:26:00,295 --> 00:26:06,180
Why is this important? Because if you imagine a hospital, for example, or a place where there is no internet access,

286
00:26:06,961 --> 00:26:09,263
It can't be connected to GPT-3, for example, to consume it.

287
00:26:12,628 --> 00:26:14,869
And if we have a giant model, it can't run either.

288
00:26:15,229 --> 00:26:16,649
Instead, now what we are saying is,

289
00:26:17,009 --> 00:26:18,610
well, you can take this model that maybe,

290
00:26:18,950 --> 00:26:22,831
for example, it can be a model that gives us some kind of medical information

291
00:26:22,911 --> 00:26:26,992
and we can have it running in a hospital without an internet connection,

292
00:26:27,012 --> 00:26:35,035
simply with a computer where it is running there and people have access to that model, right?

293
00:26:35,095 --> 00:26:36,455
And well, here we have tests, etc.

294
00:26:36,595 --> 00:26:39,776
We can see this, that they ran it in the Raspberry Pi.

295
00:26:41,137 --> 00:26:45,360
How is it possible? I leave you here an article, this is a more technical article,

296
00:26:45,380 --> 00:26:51,564
it explains a little bit how they did it, it is a little mathematical, it explains,

297
00:26:51,584 --> 00:26:55,767
it is quite good, this article does seem to get into that side, right?

298
00:26:55,787 --> 00:27:02,391
Here you can have it, you see, normally you have this model, 7 billion parameters,

299
00:27:02,531 --> 00:27:04,953
generally if you run it at normal precision,

300
00:27:06,375 --> 00:27:09,258
It's going to take up 28 GB of memory on the video card, right?

301
00:27:09,318 --> 00:27:12,161
I mean, what video card has this amount of memory?

302
00:27:12,461 --> 00:27:16,625
14 when you use it at medium precision, mid precision. 8

303
00:27:18,688 --> 00:27:35,215
7 gigs when you use it at 4 and when you use it at 4, 3.5 gigs of memory, so here you can see that there are already many GPUs that have this capacity at the moment, so you can see that this is giving access to many more people, right?

304
00:27:35,255 --> 00:27:43,958
Again, an interesting article, you can try it, here you can see it on the MacBook, on the Raspberry Pi, how it works, etc. It's pretty good.

305
00:27:44,919 --> 00:27:44,999
Now.

306
00:27:46,360 --> 00:28:04,891
The last thing we are going to see here is, well, now if I, because here we are starting from the fact that there is a model that would be Lama and then we are doing a fan tuning that would be with Alpaca, but how can we have the first model, the Lama one, right? Because this model is not open source, right?

307
00:28:04,951 --> 00:28:08,032
I mean, Facebook made it available for researchers, but...

308
00:28:09,454 --> 00:28:13,860
he told us that he does not have a commercial license, so you cannot use it for a company, for example.

309
00:28:14,080 --> 00:28:19,707
So, if we want to make our own version, for us, as we are a company or we are a country or whatever, we want to have our own version, how do we do it?

310
00:28:24,636 --> 00:28:36,109
Here what it is telling us is that if we take the table 15 of the original paper, you can see that to train that model they needed about 82,000 hours of this GPU.

311
00:28:36,150 --> 00:28:40,234
Here they realize that anything, from a dollar to the hour, does not exist.

312
00:28:43,160 --> 00:28:46,681
This is more or less between 2 and 3 dollars per hour for this type of GPU, the 80.

313
00:28:46,721 --> 00:28:49,962
So we can see that here this is going to cost us about 250,000 dollars, not 85 as the person says.

314
00:28:50,002 --> 00:28:54,203
But imagine that we do not have to think of it as individuals who are doing this, but a country, you can imagine.

315
00:28:54,263 --> 00:29:01,106
If a country wants to have its own model of language, wants to be built on this architecture and be in the language of that country,

316
00:29:01,126 --> 00:29:03,487
this is what you would get to have this type of effect.

317
00:29:12,770 --> 00:29:19,735
of models, right? And here, well, once we have it, we can then do that fine-tuning

318
00:29:19,855 --> 00:29:25,279
that we are talking about, right? And it can be run in a browser as well. And here it gives us several

319
00:29:25,339 --> 00:29:32,524
examples of that, right? We can see here how Stable Diffusion, for example, is now running in this

320
00:29:32,544 --> 00:29:38,249
Transformers library in Javascript, which is something that came out of Hive and Face a long time ago.

321
00:29:37,950 --> 00:29:50,846
very little, that means that this is running on the side of the client, it is a web page that is running on the side of the client and is running this type of models, so that is what we are seeing as the future that is going to come.

322
00:29:57,417 --> 00:30:03,539
I wanted to show you something interesting here that made this training even more efficient.

323
00:30:04,199 --> 00:30:11,161
And now they are using something called LoRa, which we saw for Stable Diffusion.

324
00:30:11,501 --> 00:30:14,702
But originally it was something that was made to train language models.

325
00:30:14,722 --> 00:30:18,443
Basically what it tells us is, let's see if it has an image here.

326
00:30:18,603 --> 00:30:19,824
No, it doesn't have an image.

327
00:30:20,464 --> 00:30:23,625
but we can see that here...

328
00:30:23,466 --> 00:30:30,614
Lora, what is it? It is basically a very economical way to train, to do fine-tuning on these models.

329
00:30:30,834 --> 00:30:38,121
Why? Because you don't need to train everything, you just need to train the parameters that are activated more within this model, so it's very little.

330
00:30:40,646 --> 00:30:48,336
and it also has a lot of optimizations, this library from Gameface and this one from Team Deadmau5, which is great.

331
00:30:48,716 --> 00:30:52,241
So what did they do here? Well, they did a fine tuning in 5 hours.

332
00:30:52,481 --> 00:30:55,705
Remember that before we had talked that the fine-tuning was in

333
00:30:57,288 --> 00:30:57,968
Create. Share. Learn.

334
00:30:57,149 --> 00:31:07,474
a cluster of 8 to 100, that's one, that is, every 100 comes out $ 8,000, they are 8 or more actually, that is, it is a huge cluster, no one has access to that.

335
00:31:07,554 --> 00:31:15,638
On the other hand, here what they did is run this model in 5 hours, not 3 hours, 5 hours in a single RTX 4090, which is a fairly expensive GPU but at least people can buy it, right?

336
00:31:15,658 --> 00:31:16,798
Who is giving us here?

337
00:31:23,023 --> 00:31:31,791
It has examples of how different groups were using this code to make their own models.

338
00:31:32,893 --> 00:31:41,661
Here we have it in Brazilian, in Chinese, in Japanese, in French and you can see here the version in Korean and in Japanese of these models.

339
00:31:41,901 --> 00:31:43,923
so if we keep watching, here's a demo

340
00:31:44,546 --> 00:31:51,029
that they made, Alpaca Lora, you can see here I wrote her an instruction, I say you are an

341
00:31:51,049 --> 00:32:00,213
AI assistant who is trained in animals, you are courteous, concise and you are not lazy, ambiguous, and here I ask her

342
00:32:00,273 --> 00:32:06,256
how are you? Tell me, tell me about the alpacas, what are they? And this is the answer she is giving me,

343
00:32:06,276 --> 00:32:11,758
the alpacas are members of the family of the camelids and they are native to South America, they are known for their

344
00:32:12,118 --> 00:32:12,999
good blah blah blah blah

345
00:32:13,520 --> 00:32:18,884
I hope you can see that the answer is quite good, quite good and this was trained in a short time.

346
00:32:19,105 --> 00:32:26,150
Now, let's see this model here, HineFace in Brazilian, what is this?

347
00:32:26,430 --> 00:32:27,211
Well, this is a team.

348
00:32:28,954 --> 00:32:31,114
They named it Cabrita. These guys are geniuses.

349
00:32:31,175 --> 00:32:33,736
And what they did here was very easy.

350
00:32:33,756 --> 00:32:37,477
They took the alpaca dataset, which we saw here.

351
00:32:37,537 --> 00:32:39,078
It was the giant JSON we saw.

352
00:32:39,098 --> 00:32:40,999
Giant JSON with 50,000 examples.

353
00:32:41,019 --> 00:32:42,540
What they did was translate it into Portuguese

354
00:32:42,580 --> 00:32:45,581
and they ran this training of Lora, which is what we are seeing here.

355
00:32:54,445 --> 00:32:59,887
and it gave them a model that works as a chat gpt but only has this, 16 megabytes,

356
00:33:00,467 --> 00:33:02,227
which is what the Lora model weighs, very little.

357
00:33:02,387 --> 00:33:04,128
And here we have the demo, which is this.

358
00:33:04,168 --> 00:33:09,149
Here we have the model and you can consume the demo if we download it, etc.

359
00:33:09,189 --> 00:33:10,450
And this is how it works.

360
00:33:10,470 --> 00:33:11,490
And here they have...

361
00:33:19,632 --> 00:33:23,814
How can I start a career as a Data Scientist?

362
00:33:24,855 --> 00:33:26,555
Write me in a form of a list.

363
00:33:26,595 --> 00:33:30,017
And here it says, start by specializing in a specific field such as

364
00:33:30,537 --> 00:33:33,518
Big Data, Computation, Bioinformatics, Statistics and blah blah blah, but

365
00:33:33,919 --> 00:33:37,520
you can see how

366
00:33:37,540 --> 00:33:39,201
how it compares, right?

367
00:33:39,221 --> 00:33:41,442
That is, the answer of Stanford with that of Cabrita.

368
00:33:41,962 --> 00:33:43,163
How can I start a career?

369
00:33:43,243 --> 00:33:48,945
Get a title of Data Scientist or Data Engineering, blah blah blah, right?

370
00:33:49,786 --> 00:33:50,026
That's it.

371
00:33:52,795 --> 00:33:55,277
putting it back. How did they do it? Because this is interesting, right?

372
00:33:55,297 --> 00:33:59,200
This means that countries can have their own model, similar to this.

373
00:33:59,220 --> 00:34:01,942
So here what it's telling us is, well, how did they do it?

374
00:34:01,962 --> 00:34:05,684
They translated the dataset into Portuguese and then they did that training,

375
00:34:05,784 --> 00:34:08,006
running it again, three hours in an A100 cluster.

376
00:34:08,026 --> 00:34:09,307
This is quite large.

377
00:34:09,327 --> 00:34:11,188
and you can see here

378
00:34:15,072 --> 00:34:17,153
Well, how were the results?

379
00:34:17,193 --> 00:34:21,914
He compares them with the pack and says, look, it's much better,

380
00:34:21,954 --> 00:34:24,375
and this can help make these language models

381
00:34:24,635 --> 00:34:27,116
in languages that are not as represented,

382
00:34:27,176 --> 00:34:27,816
such as Portuguese.

383
00:34:32,280 --> 00:34:44,434
and they trained it in Goal Collab, that's why they used the A100, so now they say, well, our next iteration is going to be something that is commercially clean, that means that they can use a base model that is, that is,

384
00:34:51,143 --> 00:34:59,369
that is free, which is not the case of Lama, Lama is the owner. So, well, we saw all these examples,

385
00:34:59,850 --> 00:35:05,995
I hope it helps you to have an idea of ​​what are the things that are being done,

386
00:35:06,015 --> 00:35:10,258
as you can see here we have a couple of languages ​​not four languages ​​

387
00:35:11,400 --> 00:35:19,265
And this is all closed, it's just some research for now, but you can imagine that as new models come out, instead of LAMA,

388
00:35:19,666 --> 00:35:27,031
that another model comes out, for example, from Stable Diffusion, and that it can be used as a base, this is going to be similar to Stable Diffusion.

389
00:35:27,271 --> 00:35:35,016
That is, many, many models will start to come out in each language, and that will make all this much more accessible.

390
00:35:35,576 --> 00:35:38,358
This is accelerating at a very, very fast pace.

391
00:35:39,920 --> 00:36:00,167
So well, this was a video of alpaca, I hope it is useful, again I tried to cover the whole topic in the best possible way, surely there are things that I forgot, I thought this was very sharp, I think it can be the basis for many changes in the future and enlarge the access of this to

392
00:36:01,128 --> 00:36:06,511
to several people who have access to different types of hardware, not only to large companies

393
00:36:06,531 --> 00:36:11,093
and I also believe that this is happening in a much faster way than expected

394
00:36:11,393 --> 00:36:16,636
maybe we were waiting for this to happen in years and the truth is happening in weeks or months

395
00:36:16,816 --> 00:36:23,599
simply, so well I hope this video is useful to you, it was something I wanted to talk about

396
00:36:23,619 --> 00:36:27,121
the truth and learn also that is why I did it so I send you a very big hug bye bye

