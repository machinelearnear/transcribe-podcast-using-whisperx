1
00:00:00,720 --> 00:00:09,623
Hello again to the channel, today we are going to make a very simple video, and the question is, do you want to try GPT-4 from OpenAI and other language models without spending a dime?

2
00:00:09,664 --> 00:00:14,505
Well, here we have the solution. Today we are going to see Open Playground,

3
00:00:14,705 --> 00:00:17,486
which is a collaborative platform that allows us to experiment with models

4
00:00:17,566 --> 00:00:22,848
of business language such as Meta, Anthropic, Google, Himephase and OpenAI.

5
00:00:23,449 --> 00:00:28,374
so let's see a little how this tool works, as always we are going to see the video divided

6
00:00:28,394 --> 00:00:33,139
into parts but there are only two parts, one is Prompt Engineering and what does this mean and the

7
00:00:33,179 --> 00:00:38,263
other is what we are seeing here so we are going to start directly with this tool, what

8
00:00:38,283 --> 00:00:43,288
we have here we have this website that I have all the links will be in the description of the video

9
00:00:43,930 --> 00:01:08,737
this is a tool that what it does is that we can put a prompt here, that is, that we have an input that we are playing with the models and then we can compare the result of this input when we send it to all these models that we are seeing here and indeed all those that we have here on the right, so in this case I asked him a question where I say look at this article and I write text and put a web page, right?

10
00:01:08,757 --> 00:01:08,857
Bye.

11
00:01:10,258 --> 00:01:17,423
Then I say, look at this web page, which is a journal article by The Economist

12
00:01:17,603 --> 00:01:20,405
that says, the career of the artificial intelligence laboratories is heating up,

13
00:01:20,465 --> 00:01:23,548
Chad GPT is not the only one in town, this came out at the end of January of 2023.

14
00:01:23,628 --> 00:01:28,812
And what I say is, look at the text that is on that web page and give me a summary.

15
00:01:28,992 --> 00:01:29,072
No?

16
00:01:36,219 --> 00:01:43,841
And I also tell you to fool around, I tell you, man, put me a strong silver accent to everything you say, right?

17
00:01:44,281 --> 00:01:47,262
So we send this submit this prompt and what does it give us back?

18
00:01:47,382 --> 00:01:49,062
Well, let's see all the models, right?

19
00:01:49,182 --> 00:01:54,124
And here I'm going to make a stop and we're going to say which are the big companies that are doing things.

20
00:01:54,584 --> 00:01:59,165
We have big companies, like Google OpenAI, for example.

21
00:01:59,987 --> 00:02:04,970
And then we have Startups, and then we have a whole part that would be open source.

22
00:02:05,190 --> 00:02:08,513
So we have what would be Anthropic Cohere, for example,

23
00:02:08,933 --> 00:02:12,155
and these would be the smallest laboratories.

24
00:02:12,516 --> 00:02:15,858
We have OpenAI, Google, and Google does a lot of open source things.

25
00:02:15,878 --> 00:02:16,539
and then we have meta.

26
00:02:17,000 --> 00:02:19,702
Facebook, which also does open source things.

27
00:02:19,742 --> 00:02:22,364
So in this case, we have a model here, which is Dantropic,

28
00:02:22,384 --> 00:02:25,547
and you can see that here I had asked him,

29
00:02:25,587 --> 00:02:28,689
I mean, I make a summary and put a silver accent and you can see that here

30
00:02:28,709 --> 00:02:31,231
he sent me a che, but the rest he writes everything to me in English.

31
00:02:31,611 --> 00:02:33,773
I mean, very well understood, but at least it seems that

32
00:02:33,793 --> 00:02:37,075
he is making a summary of the article. Let's see Lama,

33
00:02:37,335 --> 00:02:39,157
Let's see what happens.

34
00:02:38,898 --> 00:02:41,499
we can see here that it is actually inventing absolutely everything.

35
00:02:42,200 --> 00:02:43,720
It didn't submit an article, I didn't do it,

36
00:02:43,780 --> 00:02:47,703
and the only thing it is doing is inventing all these things.

37
00:02:47,723 --> 00:02:51,104
This Google Flan model is not looking at the text either,

38
00:02:51,124 --> 00:02:53,005
which makes sense because it is not instructed to do that,

39
00:02:53,065 --> 00:02:55,207
and decoding directly does absolutely anything.

40
00:02:59,630 --> 00:03:01,872
But if we look at OpenAI, GPT-4 and GPT-3,

41
00:03:01,892 --> 00:03:02,413
look at GPT-3.5,

42
00:03:02,553 --> 00:03:03,634
I'm sorry, GPT-3.5 is ChatGPT.

43
00:03:03,654 --> 00:03:10,339
Sorry, but I can't write with an Argentinian accent because I'm a language modeler and I don't have an Argentinian accent.

44
00:03:10,962 --> 00:03:14,762
However, I can provide a summary of the article you mentioned, right?

45
00:03:14,782 --> 00:03:16,843
And here it starts to tell us a little about the summary.

46
00:03:16,903 --> 00:03:20,564
But, if we see GPT-4, we will see that it starts us there very well.

47
00:03:20,604 --> 00:03:22,524
And that's why I left this example, because it starts us saying,

48
00:03:22,564 --> 00:03:26,265
Hey, friend, look, I'll tell you that this article talks about how the competition

49
00:03:26,285 --> 00:03:28,846
between the artificial intelligence laboratory is heating up all over the world.

50
00:03:28,946 --> 00:03:31,866
artificial intelligence all over the world, they are investing a lot of money.

51
00:03:31,107 --> 00:03:34,228
in research and development, and big companies like Google, Apple and Facebook

52
00:03:34,268 --> 00:03:35,448
are fighting to hire the best brains.

53
00:03:35,468 --> 00:03:39,130
You see? Now there are concerns about the concentration of talent

54
00:03:39,150 --> 00:03:42,291
and the possibility of an oligopoly in the industry, but well,

55
00:03:42,311 --> 00:03:46,253
That's what happens when things get spicy in the world of technology.

56
00:03:46,914 --> 00:03:49,275
Impressive! How is it going to write like this? Very good!

57
00:03:49,395 --> 00:03:54,398
But well, this is just an example of the things we can do.

58
00:03:54,418 --> 00:03:57,480
What you are seeing here is something completely free.

59
00:03:57,541 --> 00:04:01,323
It is a platform called Playground, Open Playground.

60
00:04:01,703 --> 00:04:04,945
It is open source, it actually has a 3.0 GPL license.

61
00:04:05,105 --> 00:04:07,907
But it is a web application that allows us to compare and run

62
00:04:08,448 --> 00:04:09,989
language models in our data.

63
00:04:15,554 --> 00:04:26,938
Now, this means that we can download it, we run it on our machine, we install it here and we start it and that already leaves us to use it on our computer, but this that we see here is not on our computer, where is this?

64
00:04:26,958 --> 00:04:29,799
Well, this, nat.dev, is the web page of Nat Friedman, who is the ex-CEO of Twitter.

65
00:04:29,819 --> 00:04:30,799
We can see it here.

66
00:04:41,543 --> 00:04:46,248
was the one that managed twitter before elon musk appeared and if you can see here this

67
00:04:46,388 --> 00:04:50,812
guy put it completely free, that is, he put this tool and said well, don't worry, I'm going to

68
00:04:50,832 --> 00:04:54,896
put all those models that we had seen before, I'll put it for free, don't worry, I'll

69
00:04:54,936 --> 00:04:56,238
for the account, everything is fine.

70
00:04:58,642 --> 00:05:01,162
And you can see here, because the guy says, what's going on, man?

71
00:05:01,182 --> 00:05:03,623
Look how the OpenAI account went, exponential.

72
00:05:03,643 --> 00:05:05,563
Why? Because people are using it, right?

73
00:05:05,583 --> 00:05:06,783
Just like we are here accessing GPT-4 or 3.5,

74
00:05:06,823 --> 00:05:08,444
a lot of people are doing it, so this for now is free,

75
00:05:08,464 --> 00:05:12,065
that's why I put it, that's why I tell it, take advantage of it.

76
00:05:12,765 --> 00:05:14,525
And well, now that we have seen this tool,

77
00:05:14,585 --> 00:05:17,526
we already know where it comes from, let's see a little, let's try it,

78
00:05:17,546 --> 00:05:19,506
to see how well it works.

79
00:05:19,566 --> 00:05:20,046
And here is a page...

80
00:05:26,888 --> 00:05:32,770
that I also put in the description. It is a page that is making us a guide to Prompt

81
00:05:32,830 --> 00:05:37,972
Engineering. What does Prompt Engineering mean? Well, this is what we are doing here, we are

82
00:05:37,992 --> 00:05:44,474
talking to the model and the way we talk to the model is very important because that depends

83
00:05:44,514 --> 00:05:45,274
how the module was trained.

84
00:05:46,336 --> 00:05:50,281
and you will see the difference now, there are models that will respond much better, right?

85
00:06:13,934 --> 00:06:20,217
these prompts that we are putting in, so first of all we are going to see a little bit what

86
00:06:20,277 --> 00:06:24,138
are the characteristics that the language models have and if we go back you will see here

87
00:06:24,519 --> 00:06:29,381
that there are a couple of things, that is, we have all the models here on the right, the oiter.ai which is

88
00:06:29,421 --> 00:06:36,284
open source, pitea, anthropic that I have to pay for, alexalpha is a German, European company and here

89
00:06:36,304 --> 00:06:41,807
we have the models that also if we click it, that is, we are going to have it available, we have

90
00:06:41,827 --> 00:06:44,228
We have High End Face, we have Lama, which is meta.

91
00:06:44,849 --> 00:06:51,454
We have Cogier, which is a startup, this is Pavo, OpenAI, and then we have several models.

92
00:06:51,594 --> 00:06:53,916
But these are the models that are being compared.

93
00:06:53,936 --> 00:07:00,361
So, see above all that we have values ​​such as temperature, topK, topKp, etc.

94
00:07:00,421 --> 00:07:01,341
All these things.

95
00:07:01,381 --> 00:07:05,384
a penalty for repetition and so on.

96
00:07:08,108 --> 00:07:11,590
So, what do we have here? We have two values that are the most important.

97
00:07:11,610 --> 00:07:13,251
We have the temperature and the top p.

98
00:07:13,511 --> 00:07:14,972
What do these two things mean?

99
00:07:15,032 --> 00:07:20,255
If we lower the temperature of the model, it means that we are going to make it more deterministic.

100
00:07:20,275 --> 00:07:25,157
That means that it will always bring us the most likely token to come out, right?

101
00:07:25,177 --> 00:07:29,380
So if we say the mouse ate the cheese, cheese will be the most likely token.

102
00:07:29,400 --> 00:07:32,221
But if we want to write a document or a text that is creative,

103
00:07:32,241 --> 00:07:32,642
not necessarily.

104
00:07:37,606 --> 00:07:42,771
we always want it to bring us the most probable, because if it is not simply repeating things that I have already read,

105
00:07:42,791 --> 00:07:48,017
we want it to generate something completely new, so for that we increase the temperature.

106
00:07:48,357 --> 00:07:54,604
These values ​​here can see that it is not, that is, it is unmarked and this is because if we click up here,

107
00:07:54,624 --> 00:07:54,724
Bye!

108
00:07:56,008 --> 00:07:58,690
to see that each model has different temperature values

109
00:07:59,031 --> 00:08:03,295
you can see that the values of Anthropic and Cloth have very high values

110
00:08:03,315 --> 00:08:05,518
this is telling us that they are more creative

111
00:08:05,578 --> 00:08:09,222
and these values, for example, GPT 4 and 3.5 have values in the middle

112
00:08:09,382 --> 00:08:13,626
that means that they are a little more factual, more deterministic.

113
00:08:14,870 --> 00:08:20,692
Going back, Top P is the same, right? Which of all the possibilities that open up within this prediction

114
00:08:20,712 --> 00:08:26,573
because, let's say, you can say a mouse eats cheese, pizza, choripan, and so on

115
00:08:26,974 --> 00:08:31,675
Choripan is possible. Grammatically, it is possible that the mouse eats a chori, but it is less likely.

116
00:08:33,056 --> 00:08:38,159
So we're going to have a list, cheese, pizza, chorizo, in that order.

117
00:08:38,259 --> 00:08:42,181
So if we say, bring me the first result of the top P,

118
00:08:42,221 --> 00:08:46,583
it's always going to return cheese, right?

119
00:08:46,604 --> 00:08:48,525
So if we have these two things to change,

120
00:08:48,565 --> 00:08:51,886
the ideal is that we don't change them at the same time, right?

121
00:08:52,547 --> 00:08:54,408
Not both, only one of the two.

122
00:08:54,748 --> 00:08:54,888
Well...

123
00:08:55,990 --> 00:09:00,614
We saw these characteristics, let's see a little bit what the prompts are, right?

124
00:09:00,634 --> 00:09:04,657
One is the generative, the sky is, and this will complete us, right?

125
00:09:04,897 --> 00:09:09,921
Let's try how it works, let's get this out, and here we have 8 models,

126
00:09:10,642 --> 00:09:12,464
Let's try what happens when we put this.

127
00:09:12,504 --> 00:09:14,185
The sky is... is what?

128
00:09:17,295 --> 00:09:20,276
Well, impressive, right? We already started with Antropic, which tells us,

129
00:09:20,316 --> 00:09:24,278
I apologize, but I don't have the ability to see the sky or determine its current state.

130
00:09:24,318 --> 00:09:28,619
I am an artificial intelligence assistant created by Antropic, blah blah blah.

131
00:09:28,659 --> 00:09:32,441
Impressive. Well, Bloom, from Hugging Face, tells us the sky is blue.

132
00:09:33,321 --> 00:09:35,642
Flan, from Google, tells us blue.

133
00:09:36,302 --> 00:09:39,203
And here, OpenAI, well, I think it's impressive, right?

134
00:09:39,223 --> 00:09:42,704
It's giving us an interesting answer.

135
00:09:42,724 --> 00:09:44,245
GPT 4 versus GPT 3.5, not just GPT.

136
00:09:46,126 --> 00:09:50,947
the sky is blue during the day dark during the night but gpt-4 tells us the sky is the

137
00:09:50,987 --> 00:09:56,728
atmosphere of the earth as an impressive view the answer of gpt-4 this is something that I was

138
00:09:56,748 --> 00:10:00,949
reading also that they say that gpt-4 is more factual more deterministic that it has less emotions

139
00:10:00,969 --> 00:10:07,351
let's say that we are going to see a little the difference in that we saw a basic prompt we see the

140
00:10:07,391 --> 00:10:12,312
elements that is what we were talking about before we do not have an instruction we have a context a

141
00:10:12,812 --> 00:10:15,692
an input data that we are going to do and an indicator.

142
00:10:16,473 --> 00:10:22,794
that the output is going to give us. These are the types, well here you have, I'm going to leave it to you,

143
00:10:22,834 --> 00:10:26,535
that is, you can see it, generally how it works is something like that, we want to

144
00:10:26,555 --> 00:10:33,056
make an instruction and say, for example, it's like talking to a person, I translated the text

145
00:10:33,076 --> 00:10:38,257
you see below into Spanish, then text, two points and we put the phrase in English, then

146
00:10:38,277 --> 00:10:44,118
we give it the instruction and we give it the input, hello, and the output is directly hello,

147
00:10:44,278 --> 00:10:45,399
The translation in Spanish.

148
00:10:46,599 --> 00:10:50,341
As examples of these prompts, we have these, which are the most basic ones.

149
00:10:50,541 --> 00:10:52,902
We make a text summary, get information from somewhere,

150
00:10:52,942 --> 00:10:55,723
ask questions and answers,

151
00:10:55,823 --> 00:10:58,664
I ask a question to a text and get an answer,

152
00:10:58,924 --> 00:11:01,464
classify my text in a conversation,

153
00:11:01,565 --> 00:11:02,865
generate a code and reason.

154
00:11:02,885 --> 00:11:07,466
This can be, if Marta bought three apples but gave two apples to Juan,

155
00:11:07,487 --> 00:11:09,127
how many apples, well, this kind of things.

156
00:11:11,809 --> 00:11:17,052
Let's see what are the techniques that exist, here we are going to see the examples, we are going to see one that is

157
00:11:17,272 --> 00:11:20,974
zero shot prompting, this means that we are asking the model directly to do

158
00:11:20,994 --> 00:11:28,679
something, to do a task, a goal, we tell it in this case without doing any kind of pre-training

159
00:11:28,719 --> 00:11:34,863
or anything, we simply tell it to classify the text in neutral, negative or positive and the text is

160
00:11:35,403 --> 00:11:39,205
I think the vacation was good, right? And the sentiment was good.

161
00:11:44,212 --> 00:11:46,293
Anthropic is telling us that it is neutral.

162
00:11:46,893 --> 00:11:49,513
HindFace is telling us that it is positive.

163
00:11:51,054 --> 00:11:52,774
Lan is telling us that it is neutral.

164
00:11:53,054 --> 00:11:56,095
OpenAI is telling us, in its two variants, that it is neutral.

165
00:11:56,195 --> 00:11:57,335
But look at how...

166
00:11:58,135 --> 00:12:00,136
Well, here, cohere, xlarge...

167
00:12:00,316 --> 00:12:02,897
Let's see, it's returning us a code.

168
00:12:02,997 --> 00:12:04,177
Anything is returning us a code.

169
00:12:04,197 --> 00:12:06,117
Cohere, what's up, man?

170
00:12:06,137 --> 00:12:08,478
Well, Anthropic gives us a good answer here.

171
00:12:08,618 --> 00:12:10,558
It would classify the text as neutral.

172
00:12:10,638 --> 00:12:13,019
The word OK suggests a neutral feeling.

173
00:12:14,601 --> 00:12:19,586
Let's see another example. This is zero shot, that means we are directly telling it what we want.

174
00:12:19,606 --> 00:12:21,528
We want it to classify the text.

175
00:12:22,149 --> 00:12:24,531
Few shot is when we give it an example.

176
00:12:25,112 --> 00:12:27,715
At the same time we ask it for something, we give it an example of what we ask for.

177
00:12:27,735 --> 00:12:31,138
This is a weird example, but it says...

178
00:12:32,281 --> 00:12:37,662
It is a small, hairy animal, native to Tanzania.

179
00:12:38,122 --> 00:12:41,263
An example in a sentence that uses the word wadpoo is

180
00:12:41,683 --> 00:12:48,105
We were traveling to Africa and we saw some wadpoos, the truth is that they are quite cute.

181
00:12:48,145 --> 00:12:54,066
To do a fardoodle means to jump up and down very fast.

182
00:12:54,466 --> 00:12:54,906
An example.

183
00:12:59,138 --> 00:13:03,360
And this is going to be quite random. It's a creative example.

184
00:13:03,380 --> 00:13:05,381
So let's see what it does to us when we put this.

185
00:13:05,401 --> 00:13:06,061
We give it an example.

186
00:13:06,081 --> 00:13:11,083
Let's say we invent a word and we give it an example of how to use that word in a sentence.

187
00:13:11,143 --> 00:13:18,085
And then we invent another word or talk about another word and we ask it to generate an example of that word in another sentence.

188
00:13:28,470 --> 00:13:39,153
Well, let's start with Antropic. Antropic is directly telling us, look, I don't know these two words, so eat it, basically.

189
00:13:39,193 --> 00:13:43,895
HeimFace generates a sentence, right? We saw a Wadpoo and he was doing a Fardoodle.

190
00:13:47,800 --> 00:13:50,523
Flan too. The frog did a fartoodle in the pond.

191
00:13:51,124 --> 00:13:54,788
And this one also seems pretty good, right?

192
00:13:54,828 --> 00:13:56,590
Kogira, now, really, is good.

193
00:13:56,630 --> 00:13:58,672
And she's also explaining the meaning.

194
00:13:59,233 --> 00:14:03,377
meaning, that is, it is something half silly, half funny

195
00:14:05,722 --> 00:14:11,623
act in a silly way, an example of a sentence that uses the word naffy, well here

196
00:14:11,683 --> 00:14:17,105
absolutely anything is being invented, so coherent, you were fine and then bad.

197
00:14:18,605 --> 00:14:26,467
OpenAI, well, chat-gpt generates two sentences for us and they are interesting, I could not contain my

198
00:14:27,127 --> 00:14:30,828
my surprise and I started Fardoodle when I heard the news well ok

199
00:14:34,070 --> 00:14:36,894
we are going to see this one called

200
00:14:37,595 --> 00:14:38,376
chain of thought

201
00:14:38,656 --> 00:14:41,200
and in this case, if we take the first example

202
00:14:41,220 --> 00:14:41,680
For example...

203
00:14:44,164 --> 00:14:45,005
Create. Share. Learn.

204
00:14:43,966 --> 00:14:46,987
And it's a very interesting concept of chain of thought.

205
00:14:47,007 --> 00:14:48,508
And we ask the model, for example,

206
00:14:48,528 --> 00:14:52,670
this would be like a few shot, right? Think of it like a few shot.

207
00:14:52,690 --> 00:14:53,410
We give it an example.

208
00:14:54,831 --> 00:14:56,691
Rogelio had five tennis balls.

209
00:14:56,851 --> 00:14:58,872
He bought two more tennis balls cans.

210
00:14:58,892 --> 00:15:00,973
Each of those cans had three tennis balls.

211
00:15:00,993 --> 00:15:02,834
How many cans does he have in total?

212
00:15:03,254 --> 00:15:04,835
The answer is eleven.

213
00:15:04,855 --> 00:15:06,216
This is the information we give him.

214
00:15:06,236 --> 00:15:07,476
We simply tell him it's eleven.

215
00:15:07,496 --> 00:15:10,818
But we don't tell him how he has to think about the problem.

216
00:15:10,838 --> 00:15:10,918
and

217
00:15:12,159 --> 00:15:14,781
So when we give the next example, we tell it that the cafeteria had 23 apples,

218
00:15:14,801 --> 00:15:16,962
they used 20 to make lunch, and they bought 6 more.

219
00:15:16,982 --> 00:15:18,423
How many apples do they have?

220
00:15:19,443 --> 00:15:20,944
And here the model says that the answer is 27.

221
00:15:21,044 --> 00:15:21,764
Of course, see you later.

222
00:15:24,507 --> 00:15:28,129
On the other hand, when we use this chain of thought and we give it the first example,

223
00:15:28,809 --> 00:15:33,112
notice that we are saying that Rogelio started with 5 balls, then he bought 2 cans with 3 each,

224
00:15:33,132 --> 00:15:34,553
so we have 5 plus 6, 11, the answer is 11.

225
00:15:34,753 --> 00:15:39,016
And since we gave him this, when we ask him this question again, the second time,

226
00:15:39,036 --> 00:15:43,219
The model will respond in the same way that we responded here, in the example.

227
00:15:46,182 --> 00:15:52,624
so now it starts to think and as it is thinking, let's say it is putting it in this sequence, it

228
00:15:52,744 --> 00:15:56,826
can answer correctly, so the answer is 9, which is the correct number,

229
00:15:56,846 --> 00:16:01,308
so let's see here how this works, so we copy this prompt, we put it here and we

230
00:16:01,328 --> 00:16:06,190
submit and we are going to see which model is the one that works best, so the question here is

231
00:16:11,313 --> 00:16:13,294
The question here is, what is the answer?

232
00:16:13,314 --> 00:16:14,254
This.

233
00:16:14,714 --> 00:16:17,536
The number has to be 41, and the answer is false.

234
00:16:18,977 --> 00:16:22,198
So here we can see, well, here it says all the numbers.

235
00:16:22,478 --> 00:16:23,679
It gives us 25, and the answer is false.

236
00:16:23,719 --> 00:16:23,959
Wrong.

237
00:16:24,219 --> 00:16:27,041
Here it gives us 36, and the answer is true.

238
00:16:27,061 --> 00:16:27,841
Wrong.

239
00:16:29,862 --> 00:16:30,162
Wrong.

240
00:16:33,384 --> 00:16:33,724
Google.

241
00:16:35,705 --> 00:16:37,006
It gives us 97, and the answer is wrong.

242
00:16:37,086 --> 00:16:39,427
Let's see GPT-4 and ChatGPT.

243
00:16:42,830 --> 00:16:45,492
Putting all this together gives us 41. The answer is false.

244
00:16:46,012 --> 00:16:47,553
Both produce the same result.

245
00:16:47,633 --> 00:16:49,634
The answer is correct.

246
00:16:49,694 --> 00:16:52,416
We see Cogier again doing whatever.

247
00:16:52,836 --> 00:16:55,138
We see Lama again doing whatever.

248
00:16:55,318 --> 00:16:57,239
Hindface with Bloom, whatever.

249
00:16:57,259 --> 00:16:58,439
But at least the result is better.

250
00:16:58,460 --> 00:16:59,180
But these two, whatever.

251
00:16:59,200 --> 00:17:00,381
Let's continue here.

252
00:17:00,401 --> 00:17:01,802
This is what would be the

253
00:17:08,567 --> 00:17:13,831
own consistency, right? So here we want it to self-reference when we do the prompt

254
00:17:14,711 --> 00:17:21,316
When I was 6 years old, my sister was half my age, that is, I was 3 years old. Now that I am 70, what age does my sister have?

255
00:17:22,297 --> 00:17:22,457
No?

256
00:17:25,579 --> 00:17:25,959
Let's see.

257
00:17:26,960 --> 00:17:30,262
Here he answered wrong, it says 35.

258
00:17:30,382 --> 00:17:32,744
I mean, he did half of 70.

259
00:17:32,784 --> 00:17:34,065
This is already correct.

260
00:17:34,345 --> 00:17:34,806
There you go

261
00:17:36,788 --> 00:17:43,513
Sorry, proper consistency would be this way of writing the language we have.

262
00:17:43,533 --> 00:17:47,435
This way is when we do an arithmetic reasoning.

263
00:17:47,455 --> 00:17:51,117
But well, let's see if we do this, who answers us, right?

264
00:17:51,838 --> 00:17:55,760
Well, notice how Antropic is already taking this input and is breaking it step by step, right?

265
00:17:56,020 --> 00:17:59,562
And here it is telling us, when you were 6 years old, your sister was half your age.

266
00:17:59,582 --> 00:18:05,306
So she lived two or three years. So your sister is three years older?

267
00:18:08,409 --> 00:18:12,371
when you were 6 years old. Now, you are 70 years old

268
00:18:13,792 --> 00:18:15,634
3 years old when you were 6 years old

269
00:18:15,654 --> 00:18:16,194
now you are...

270
00:18:16,214 --> 00:18:18,936
If you are 70 years old, your sister would be 72, 35, 35, blah blah blah

271
00:18:18,996 --> 00:18:22,598
I mean, anyone, anyone. You started well and ended up doing anything.

272
00:18:22,618 --> 00:18:23,619
Let's see the other module, Cloth 1.2

273
00:18:30,404 --> 00:18:42,978
I had 6 years, so I had 3, now I have 70, 70 minus 6 is 64, 30 plus 64 is 67, well here I do not know what magic he did here to think about this but the answer is correct 67 years, so we can say that it is correct, we are going to see Lama of meta

274
00:18:49,787 --> 00:19:08,171
My mother has three daughters, January, February and March, February, February, well, anything, plum says 40 is wrong, flan 30 is wrong, cohere, let's see, let's see, cohere, well again 35, incorrect, let's see chat gpt and gpt 4, well chat gpt, wrong, your sister is 64 years old, wrong, incorrect

275
00:19:12,853 --> 00:19:17,796
GPT-4, when you were six years old your sister was half your age, which means that she is three

276
00:19:17,816 --> 00:19:23,659
years younger than you, now that you are 70, your sister is 70 minus 3, 67 years old. GPT-4, the best

277
00:19:23,859 --> 00:19:31,323
answer at this time. Let's see what happens when we put this in self consistency,

278
00:19:31,903 --> 00:19:35,685
Let's see if we can get the other models to have a better response.

279
00:19:46,684 --> 00:19:53,628
Well, let's see, it's going to have to do some thinking. 67, 69, 35. Let's see what it gives us back.

280
00:19:53,648 --> 00:19:54,709
No? And here you have to see if...

281
00:20:00,555 --> 00:20:06,859
if we are not cutting the answer, because here we have 200 tokens

282
00:20:07,039 --> 00:20:10,661
so I don't know if we are cutting the answer

283
00:20:10,801 --> 00:20:14,523
here you can see how chatgpt and gpt4 have the same answer, 67

284
00:20:14,563 --> 00:20:16,344
cohere is putting money, a dress costs 12, etc.

285
00:20:16,384 --> 00:20:18,365
well, anything, cohere

286
00:20:18,745 --> 00:20:19,986
let's see these people

287
00:20:20,066 --> 00:20:21,487
Is this free or do I have to pay for it?

288
00:20:32,074 --> 00:20:37,778
Well, you have to pay. How much? Two and a half each thousand, that means that it comes out 0.0025

289
00:20:37,918 --> 00:20:42,841
And how much does ChatGPT come out?

290
00:20:42,881 --> 00:20:46,903
Well, ChatGPT comes out 0.002, that is, cheaper.

291
00:20:46,943 --> 00:20:53,087
This, this result that we have here, which is anything, is cheaper than this.

292
00:20:53,107 --> 00:20:56,709
It is more expensive than this, which is fine, it is well done.

293
00:20:56,869 --> 00:20:57,910
Let's see how much...

294
00:21:01,453 --> 00:21:05,475
How much money does Cohere have?

295
00:21:05,495 --> 00:21:08,757
Well, they raised 165 million dollars to make that model that we just saw there.

296
00:21:08,837 --> 00:21:13,840
So, why do I say this? Because we always think of these big Silicon Valley companies

297
00:21:13,880 --> 00:21:17,783
as if they were generating incredible products and here you can see how with a product

298
00:21:21,706 --> 00:21:31,889
I don't say mediocre, but it is not of the same quality as the market leader, it can also be in the game, it can have a giant financing and stay there.

299
00:21:31,929 --> 00:21:36,270
We hope that GoGear can improve the quality of their models and also the same with

300
00:21:36,350 --> 00:21:41,871
Anthropic, Meta, Google, etc. and that this makes science advance a lot more.

301
00:21:42,892 --> 00:21:55,356
So what I want to do here is to compare the last thing, the video and the text and all the description, I am doing this with GPT-4, I have the model available here.

302
00:21:55,857 --> 00:21:59,138
And what I'm saying here is the system, this is the context.

303
00:21:59,158 --> 00:22:09,901
I'm saying, you are YouTube GPT, a language model trained by OpenAI, you are a YouTuber expert and you are concise, you do not skip any detail and you write scientifically when possible.

304
00:22:10,802 --> 00:22:11,362
Create. Share. Learn.

305
00:22:10,722 --> 00:22:15,405
And now I tell it the input, I want you to read this website, which is the page we just saw.

306
00:22:15,665 --> 00:22:19,126
Oh, that's why I was taking it, because I had put this, the chain of thought.

307
00:22:20,067 --> 00:22:23,929
I want you to read this other website, which is the repo of OpenPlayground.

308
00:22:24,129 --> 00:22:28,011
And now I tell it, now I want you to give me three examples of a title and a description

309
00:22:28,431 --> 00:22:31,773
for a new YouTube video that I'm wanting to record

310
00:22:31,853 --> 00:22:34,254
about this new tool called Open Playground.

311
00:22:34,936 --> 00:22:40,259
where you can compare blah blah blah blah blah no, do not give me a title that is clickbait and try to

312
00:22:40,279 --> 00:22:44,082
write a description that is a little longer, do not invent things, use the information

313
00:22:44,142 --> 00:22:49,886
of the links that I gave you, I do not want you to talk about chain of thought and I want you to take into account the

314
00:22:49,926 --> 00:22:54,169
fact that gpt4 can be used for free with this tool and then to forget again

315
00:22:54,329 --> 00:23:01,313
I tell you to write with a strong Argento accent and you can see the things that it generates for me, not here

316
00:23:01,353 --> 00:23:03,755
And well, this is what I ended up using in the description.

317
00:23:04,477 --> 00:23:12,543
Now, what I do want to do is to copy this and paste it here, let's see the last example.

318
00:23:13,784 --> 00:23:17,747
Let's see what it does to us, right?

319
00:23:18,607 --> 00:23:19,028
Well, let's see.

320
00:23:19,068 --> 00:23:19,808
Hi, I'm U2GPT.

321
00:23:19,908 --> 00:23:24,572
Well, Antropic, we can see that it didn't do anything to us.

322
00:23:25,172 --> 00:23:28,314
Testing the large language modules with, I don't know, Antropic Cloud.

323
00:23:28,835 --> 00:23:30,856
Cloud is generating something for us, at least.

324
00:23:31,217 --> 00:23:33,238
that is, by testing the language models.

325
00:23:32,939 --> 00:23:33,660
Good, good.

326
00:23:35,220 --> 00:23:37,121
Lama is not doing anything to us.

327
00:23:37,682 --> 00:23:38,142
Go here.

328
00:23:39,703 --> 00:23:41,223
If you can, if you can, don't worry.

329
00:23:41,343 --> 00:23:42,664
I will provide a text to a voice.

330
00:23:42,784 --> 00:23:43,785
Impressive. Anything.

331
00:23:43,805 --> 00:23:44,405
Let's see.

332
00:23:44,425 --> 00:23:44,585
Well...

333
00:23:48,148 --> 00:23:50,469
GPT-4, we have this, and, well, GPT-Chat too, right?

334
00:23:50,549 --> 00:23:52,110
I mean, they also make us things that are good.

335
00:23:52,130 --> 00:23:53,571
Maybe this one is even better.

336
00:23:53,671 --> 00:23:56,412
It compares the best of the free market.

337
00:23:56,432 --> 00:23:58,133
And it sounds good, this one, eh?

338
00:23:58,153 --> 00:23:59,354
Maybe we'll use this one.

339
00:23:59,374 --> 00:24:02,275
Look, what's the best language mode? Blah, blah, blah.

340
00:24:02,295 --> 00:24:02,495
go out...

341
00:24:04,337 --> 00:24:12,204
both are good, interesting, I wanted to leave you this page for now it is free so I would say

342
00:24:12,224 --> 00:24:18,589
use it, try it, you can use GPT-4 3.5 here, you can see how it works, you can see a little in what

343
00:24:18,609 --> 00:24:25,415
state we are, because it is said that machines are going to dominate the world and in general this is

344
00:24:25,435 --> 00:24:29,618
That is the current state of things. It is neither more nor less than this.

345
00:24:30,381 --> 00:24:38,546
So I would say that you can practice, have this page, you can practice a little bit with the things that are written here,

346
00:24:38,566 --> 00:24:41,948
talk to the model and see what works better, what works worse, right?

347
00:24:57,271 --> 00:25:03,115
but I don't know if it's the same exact model as the one we have here or the one we have here

348
00:25:03,135 --> 00:25:07,839
so with that I want to thank you for being there until the end

349
00:25:07,879 --> 00:25:10,681
I hope this tool will be useful to you, I really thought it was very good

350
00:25:10,701 --> 00:25:14,704
and since we don't know how long it will last, I really wanted to share it now

351
00:25:14,824 --> 00:25:16,806
so you can take a look and try GPT-4 for free

352
00:25:16,886 --> 00:25:17,987
So I send you a big hug. Bye Bye!

